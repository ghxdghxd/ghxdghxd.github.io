{"pages":[{"title":"About","text":"","tags":"pages","url":"https://ghxdghxd.github.io/pages/about.html"},{"title":"ROC曲线","text":"ROC曲线 接收者操作特征曲线 （receiver operating characteristic curve），简称ROC曲线是一种坐标图式的分析工具，用于： 选择最佳的信号侦测模型、舍弃次佳的模型 在同一模型中设定最佳阈值 ROC分析的是二元分类模型（如阳性/阳性，有病/没病）： ROC空间 ROC空间将伪阳性率（FPR）定义为 X 轴，真阳性率（TPR）定义为 Y 轴。 TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。 TPR=TP/(TP+FN) FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。 FPR=FP/(FP+TN)","tags":"统计建模","url":"https://ghxdghxd.github.io/ROC.html"},{"title":"git submodule的用法","text":"常用命令 git clone <repository> --recursive 递归的方式克隆整个项目 git submodule add <repository><path> 添加子模块 git submodule init 初始化子模块 git submodule update 更新子模块 git submodule foreach git pull 拉取所有子模块 如何使用 1. 创建带子模块的版本库 例如我们要创建如下结构的项目 project | --moduleA | --readme.txt 创建project版本库，并提交readme.txt文件 git init --bare project.git git clone project.git project1cd project1 echo \"This is a project.\" > readme.txt git add . git commit -m \"add readme.txt\" git push origin master cd .. 创建moduleA版本库，并提交a.txt文件 git init --bare moduleA.git git clone moduleA.git moduleA1 cd moduleA1 echo \"This is a submodule.\" > a.txt git add . git commit -m \"add a.txt\" git push origin master cd .. 在project项目中引入子模块moduleA，并提交子模块信息 cd project1 git submodule add ../moduleA.git moduleA git statusgit diff git add . git commit -m \"add submodule\" git push origin master cd .. 使用git status可以看到多了两个需要提交的文件，其中.gitmodules指定submodule的主要信息，包括子模块的路径和地址信息，moduleA指定了子模块的commit id，使用git diff可以看到这两项的内容。这里需要指出父项目的git并不会记录submodule的文件变动，它是按照commit id指定submodule的git header，所以.gitmodules和moduleA这两项是需要提交到父项目的远程仓库的。 On branch master Your branch is up-to-datewith 'origin/master' . Changes to be committed: ( use \"git reset HEAD ...\" to unstage ) new file: .gitmodules new file: moduleA 2. 克隆带子模块的版本库 方法一，先clone父项目，再初始化submodule，最后更新submodule，初始化只需要做一次，之后每次只需要直接update就可以了，需要注意submodule默认是不在任何分支上的，它指向父项目存储的submodule commit id。 git clone project.git project2 cd project2 git submodule init git submodule update cd .. 方法二，采用递归参数--recursive，需要注意同样submodule默认是不在任何分支上的，它指向父项目存储的submodule commit id。 git clone project.git project3 --recursive git submodule update --init --recursive 3. 修改子模块 修改子模块之后只对子模块的版本库产生影响，对父项目的版本库不会产生任何影响，如果父项目需要用到最新的子模块代码，我们需要更新父项目中submodule commit id，默认的我们使用git status就可以看到父项目中submodule commit id已经改变了，我们只需要再次提交就可以了。 cd project1/moduleA git branch echo \"This is a submodule.\" > b.txt git add . git commit -m \"add b.txt\" git push origin master cd .. git status git diff git add . git commit -m \"update submodule add b.txt\" git push origin master cd .. 4. 更新子模块 更新子模块的时候要注意子模块的分支默认不是master。 方法一，先pull父项目，然后执行 git submodule update ，注意moduleA的分支始终不是master。 cd project2 git pull git submodule update cd .. 方法二，先进入子模块，然后切换到需要的分支，这里是master分支，然后对子模块pull，这种方法会改变子模块的分支。 cd project3/moduleA git checkout master cd .. git submodule foreach git pull cd .. 5. 删除子模块 网上有好多用的是下面这种方法 git rm --cached moduleA rm -rf moduleA rm .gitmodules vim .git/config 删除submodule相关的内容，例如下面的内容 [ submodule \"moduleA\" ] url = /Users/nick/dev/nick-doc/testGitSubmodule/moduleA.git 然后提交到远程服务器 git add . git commit -m \"remove submodule\" 但是我自己本地实验的时候，发现用下面的方式也可以，服务器记录的是.gitmodules和moduleA，本地只要用git的删除命令删除moduleA，再用git status查看状态就会发现.gitmodules和moduleA这两项都已经改变了，至于.git/config，仍会记录submodule信息，但是本地使用也没发现有什么影响，如果重新从服务器克隆则.git/config中不会有submodule信息。 git rm moduleA git status git commit -m \"remove submodule\" git push origin master","tags":"工具包","url":"https://ghxdghxd.github.io/git-submodule.html"},{"title":"meta Analysis","text":"metafor document An Overview of Functions in the metafor Package Viechtbauer gesis ma with metafor meta-analysis from odds ratios and confidence intervals using metafor dm <- structure ( list ( or = c ( 1.6 , 4.4 , 1.14 , 1.3 , 4.5 ), cill = c ( 1.2 , 2.9 , 0.45 , 0.6 , 3.2 ), ciul = c ( 2 , 6.9 , 2.86 , 2.7 , 6.1 )), . Names = c ( \"or\" , \"cill\" , \"ciul\" ), class = \"data.frame\" , row.names = c ( NA , -5L )) dm $ logor <- log ( dm $ or ) dm $ se1 <- ( log ( dm $ ciul ) - dm $ logor ) / 1.96 dm $ se2 <- ( dm $ logor - log ( dm $ cill )) / 1.96 dm $ se <- ( dm $ se1 + dm $ se2 ) / 2 library ( metafor ) dmres <- rma.uni ( yi = logor , sei = se , data = dm ) pdf () forest ( dmres , atransf = exp , showweights = T , mlab = \"rsid\" , slab = paste0 ( \"study\" , 1 : 5 )) dev.off ()","tags":"统计建模","url":"https://ghxdghxd.github.io/meta.html"},{"title":"archlinux安装与配置","text":"archlinux安装 # u盘启动后 # 连接网络 wifi-memu mount /dev/sda1 /mnt mkdir -p /mnt/home mount /dev/sda2 /mnt/home # 修改中国镜像源,如163.com vi /ect/pacman.d/mirrorlist pacstrap -i /mnt base base-devel #生成挂载文件fstab genfstab -U /mnt >> /mnt/etc/fstab archlinux 初步配置 #切换到archlinux arch-chroot /mnt /bin/bash 本地语言 vi /etc/locale.gen en_US.UTF-8 UTF-8 zh_CN.UTF-8 UTF-8 #生效 locale-gen echo LANG = en_US.UTF-8 > /etc/locale.conf 时区 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # 或 # 按提示选择时区 tzselect #设置硬件时间 hwclock --systohc --utc grub引导系统 # 支持grub和EFI，可只选grup pacman -S grub efibootmgr grub-install --target = i386-pc --recheck --debug /dev/sda grup-mkconfig -o /boot/grub/grub.cfg 主机名 echo Garch >> /etc/hostname 网络配置 # 有线 systemctl enable dhcpcd.service # 无线 pacman -S iw wpa_supplicant dialog archlinux 配置 # 最小安装 # X桌面 pacman -S xorg-server # 显卡驱动 pacman -S xf86-video-ati pacman -S gnome gnome-tweak-tool pacman -S ttf-ubuntu # 可选","tags":"系统管理","url":"https://ghxdghxd.github.io/archlinux.html"},{"title":"docker安装与配置","text":"docker centos yum install docker tee /etc/yum.repos.d/docker.repo <<-'EOF' [dockerrepo] name=Docker Repository baseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/ enabled=1 gpgcheck=1 gpgkey=https://yum.dockerproject.org/gpg EOF sed -i 's/other_args=\\\"\\\"/other_args=\\\"--graph=\\/share\\/apps\\/docker\\\"/g' /etc/sysconfig/docker for i in ` seq 1 8 ` ; do sudo scp /etc/yum.repos.d/docker.repo compute-0- $i :/etc/yum.repos.d/docker.repo done rocks run host \"yum install docker-engine\" rocks run host \"sed -i 's/other_args=\\\"\\\"/other_args=\\\"--graph=\\/share\\/apps\\/docker\\\"/g' /etc/sysconfig/docker\" 手动安装 # 手动安装centos6.5 一些需要安装 yum remove docker-engine cd /share/apps/until/docker/ yum install ./lua-filesystem-1.4.2-1.el6.x86_64.rpm yum install ./lxc-libs-1.0.11-1.el6.x86_64.rpm yum install ./lua-lxc-1.0.11-1.el6.x86_64.rpm yum install ./lua-alt-getopt-0.7.0-1.el6.noarch.rpm yum install ./lxc-1.0.11-1.el6.x86_64.rpm yum install ./docker-io-1.7.1-2.el6.x86_64.rpm wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo yum install device-mapper-event-libs service docker restart 安装错误 # 下面错误： /usr/bin/docker: relocation error: /usr/bin/docker: symbol dm_task_get_info_with_deferred_remove, version Base not defined in file libdevmapper.so.1.02 with link time reference fix: $ sudo yum install device-mapper-event-libs # 如果无法安装，重新更新 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo # 然后再安装 docker应用 启动docker service docker start 添加用户 # 添加docker group： sudo groupadd docker # 将当前用户添加到docker组： sudo gpasswd -a ${ USER } docker # 重启docker服务： sudo service docker restart # 开机启动 chkconfig docker on 修改镜像和容器的存放路径 # /etc/sysconfig/docker加入： other_args = \"--graph=/data/docker\" # 停止Docker服务 service docker stop # 备份数据到新的存放路径 cp -rf /var/lib/docker /data/ # 修改备份/var/lib/docker路径 mv /var/lib/docker { ,.bak } # 启动Docker服务 service docker start # 测试Docker服务 docker info 用法 查看镜像 docker images 查找镜像 docker search 查看容器 docker ps -a 运行容器 docker run 将宿主机的/var/data挂载到容器中的/data: docker run -tdi -v /var/data:/data centos 如果ls: cannot open directory '.': Permission denied 修改/etc/sysconfig/docker，OPTIONS去掉--selinux-enabled","tags":"系统管理","url":"https://ghxdghxd.github.io/docker.html"},{"title":"网球拍的平衡点","text":"网球拍平衡点测量 这个是每份点得出来的公式（pts点，inch英寸） 1pts = 1/8 inch = 1/8 * 2.54cm = 0.3175cm 下面以标准拍子27英寸长度为例，换算出是68.5cm，那中心点就是34.25cm。然后假设你所量出平衡点到拍底的距离为h。 如果大于34.25，则是（h-34.25）/0.3175=T，就是T点头重 如果小于34.25，则是（34.25-h）/0.3175=T，就是T点头轻 图中可知，此时拍子是完全平衡状态，只需测量纸片到底盖的距离就可以了，按这个方法测量出我的拍子是32.34cm，套用公式: （34.25-32.34）÷0.3175=6.015，也就是6点头轻了！ 另附上球拍头轻和头重的优劣: 头轻拍更灵活易于控制，能让选手在网前有不错的表现，但是不能提供足够大的力量。头重拍，灵活性差，但能提供额外的力量更有利于底线的击球。一般专业的球拍都是头轻拍或者是平衡拍，因为这样更利于网前技术的发挥，而且专业球员都有很好的身体素质可以自身去发力。而初学拍比较多的是头重拍，这样能使初学者并不需要太多的发力就能击出力量较大的球。","tags":"兴趣爱好","url":"https://ghxdghxd.github.io/tennis-racquet.html"},{"title":"终端显示颜色","text":"echo显示带颜色，需要使用参数-e 格式如下: echo -e \"\\033[字背景颜色;文字颜色m字符串\\033[0m\" 例如: echo -e \"\\033[41;37m TonyZhang \\033[0m\" 其中41的位置代表底色, 37的位置是代表字的颜色 注： 1、字背景颜色和文字颜色之间是英文的\"\"\"\" 2、文字颜色后面有个m 3、字符串前后可以没有空格，如果有的话，输出也是同样有空格 下面看几个例子： echo -e \"\\033[30m 黑色字 \\033[0m\" echo -e \"\\033[31m 红色字 \\033[0m\" echo -e \"\\033[32m 绿色字 \\033[0m\" echo -e \"\\033[33m 黄色字 \\033[0m\" echo -e \"\\033[34m 蓝色字 \\033[0m\" echo -e \"\\033[35m 紫色字 \\033[0m\" echo -e \"\\033[36m 天蓝字 \\033[0m\" echo -e \"\\033[37m 白色字 \\033[0m\" echo -e \"\\033[40;37m 黑底白字 \\033[0m\" echo -e \"\\033[41;37m 红底白字 \\033[0m\" echo -e \"\\033[42;37m 绿底白字 \\033[0m\" echo -e \"\\033[43;37m 黄底白字 \\033[0m\" echo -e \"\\033[44;37m 蓝底白字 \\033[0m\" echo -e \"\\033[45;37m 紫底白字 \\033[0m\" echo -e \"\\033[46;37m 天蓝底白字 \\033[0m\" echo -e \"\\033[47;30m 白底黑字 \\033[0m\" 控制选项说明 ： 代码 作用 \\33[0m 关闭所有属性 \\33[1m 设置高亮度 \\33[4m 下划线 \\33[5m 闪烁 \\33[7m 反显 \\33[8m 消隐 \\33[30m -- \\33[37m 设置前景色 \\33[40m -- \\33[47m 设置背景色 \\33[nA 光标上移n行 \\33[nB 光标下移n行 \\33[nC 光标右移n行 \\33[nD 光标左移n行 \\33[y;xH 设置光标位置 \\33[2J 清屏 \\33[K 清除从光标到行尾的内容 \\33[s 保存光标位置 \\33[u 恢复光标位置 \\33[?25l 隐藏光标 \\33[?25h 显示光标","tags":"系统管理","url":"https://ghxdghxd.github.io/terminal-color.html"},{"title":"hotnet2","text":"hotnet2是一种新型计算机算法，能够筛选庞大的遗传数据，发现相互作用基因，而这些基因一旦突变就会导致多种癌症的发生发展。 背景 预先定义一个合理的基因集合或组合的统计需求 标准化分析突变相关通路及蛋白复合物的方法 这项研究没有选择癌症遗传学研究，而是采用了与众不同的方式，寻找癌症样品中频繁出现的单个基因的突变。基因并不会常常独自作战，主要还是与其它基因形成网络和途径，调控细胞功能。在某些情况下，途径中多个基因中出现一个突变，就会引发故障发生，导致癌症。因为有害突变可以分布在多个这样的基因网络，因此难以通过统计检验发现它们。 而Hotnet2运算方法则能在网络水平上分析基因，帮助科学家们识别罕见，但又重要的癌症突变。 HotNet2 算法是通过将病患突变数据投射到一张基因相互作用图谱上，然后寻找比偶发突变更常见的突变之间的相互作用网络，这一程序能作为heat sources寻找经常突变的基因。通过分析图谱上分布和聚集的方式，HotNet2 能找到与癌症相关的的\"热\"网络。 Hotnet 的最初版本已经被用于识别急性髓细胞白血病、卵巢癌和几个其它类型癌症中的重要网络，目前这一版本也经过修改，可以用于处理更大和更复杂的泛癌症数据集。 subnetworks.json结构 stats : {Minimum edge weight δ: { Minimum subnetwork size1 : {expected : XXX, observed : XXX, pval : XXX} Minimum subnetwork size2 : { expected : XXX, observed : XXX, pval : XXX} }} deltas : [ deltas1, deltas2, deltas3, deltas4] Minimum edge weight δ mutation_matrices : {deltas 1:{}, deltas2 : {}, deltas3 : {}, deltas4 : {}} 基因不同位点的类型（snv indel 或 cnv) typeToSamples subnetworks：{deltas :[ network0, network1] } network: {edges :{ ks Minimum subnetwork size sampleToTypes： 样本类型","tags":"生信软件","url":"https://ghxdghxd.github.io/hotnet2.html"},{"title":"git的一般用法","text":"Git用法 1 建立仓库 远程 git remote add origin git@github.com:ghxdghxd $NAME .git 本地(初始化) git init 2 常用操作 拉取 git pull origin master 提交 git add *.py git commit -m \"message\" git push origin master/dev/develop 重命令与删除 git rm git mv 3 分支操作 主支 修补 发布 开发 功能 master hotfix release develop feature git branch /-a/r # 查看本地/全部/远程分支 git branch [ name ] # 建立分支 git branch -d [ name ] # 删除分支 git checkout -b [ name ] origin/develop # 建立并切换开发分支 git checkout [ name ] # 切换分支 git merge --no-ff [ name ] # 合并分支 git push origin dev:develop # 本地分支提交到远程 push命令用于将本地分支的更新，推送到远程主机。 git push <远程主机名> <本地分支名>:<远程分支名> git pull类似: git pull <远程分支>:<本地分支> 注意，分支推送顺序的写法是<来源地>:<目的地>， 所以git pull是<远程分支>:<本地分支>，而git push是<本地分支>:<远程分支>。 如果省略远程分支名，则表示将本地分支推送与之存在\"追踪关系\"的远程分支(通常两者同名)，如果该远程分支不存在，则会被新建。 git push origin master 上面命令表示，将本地的master分支推送到origin主机的master分支。如果后者不存在，则会被新建。 如果省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支。 git push origin :master 等同于 git push origin --delete master 上面命令表示删除origin主机的master分支。 如果当前分支与远程分支之间存在追踪关系，则本地分支和远程分支都可以省略。 git push origin 上面命令表示，将当前分支推送到origin主机的对应分支。 如果当前分支只有一个追踪分支，那么主机名都可以省略。 git push 如果当前分支与多个主机存在追踪关系，则可以使用-u选项指定一个默认主机，这样后面就可以不加任何参数使用git push。 git push -u origin master 上面命令将本地的master分支推送到origin主机，同时指定origin为默认主机，后面就可以不加任何参数使用git push了。 不带任何参数的git push，默认只推送当前分支，这叫做simple方式。此外，还有一种matching方式，会推送所有有对应的远程分支的本地分支。Git 2.0版本之前，默认采用matching方法，现在改为默认采用simple方式。如果要修改这个设置，可以采用git config命令。 git config --global push.default matching 或者 git config --global push.default simple 还有一种情况，就是不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用–all选项。 git push --all origin 上面命令表示，将所有本地分支都推送到origin主机。 如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做git pull合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用–force选项。 git push --force origin 上面命令使用–force选项，结果导致在远程主机产生一个\"非直进式\"的合并(non-fast-forward merge)。除非你很确定要这样做，否则应该尽量避免使用–force选项。 最后，git push不会推送标签(tag)，除非使用–tags选项。 git push origin --tags 中文乱码 git config --global core.quotepath false core.quotepath设为false的话，就不会对0x80以上的字符进行quote。中文显示正常。 gitignore忽略文件 1、配置语法： 以斜杠\"/\"开头表示目录； 以星号\"*\"通配多个字符； 以问号\"?\"通配单个字符 以方括号\"[]\"包含单个字符的匹配列表； 以叹号\"!\"表示不忽略(跟踪)匹配到的文件或目录； 此外，git 对于 .ignore 配置文件是按行从上到下进行规则匹配的，意味着如果前面的规则匹配的范围更大，则后面的规则将不会生效； 2、示例： （1）规则：fd1/* 说明：忽略目录 fd1 下的全部内容；注意，不管是根目录下的 /fd1/ 目录，还是某个子目录 /child/fd1/ 目录，都会被忽略； （2）规则：/fd1/* 说明：忽略根目录下的 /fd1/ 目录的全部内容； （3）规则： /* !.gitignore !/fw/bin/ !/fw/sf/ 说明：忽略全部内容，但是不忽略 .gitignore 文件、根目录下的 /fw/bin/ 和 /fw/sf/ 目录； warning: LF will be replaced by CRLF 在Windows环境下使用git进行add的时候，会提示如下warning: \"warning:LF will be replacee by CRLF\"。 这是因为在Windows中的换行符为CRLF，而在Linux中的换行符为LF。 在git创建的项目中换行符为LF，而执行git add时，系统会提示LF将被转换为CRLF。 解决的办法很简单，禁止git的自动转换即可。 git config --global core.autocrlf false //禁用自动转换","tags":"工具包","url":"https://ghxdghxd.github.io/git.html"},{"title":"之感","text":"话多应知，话少需明 前人看世界，后者品人生 棋逢对手 尽兴，将遇良才 榨干——干的漂亮 有点意思 一个男人在他该出现的时候，总也不出现，那有他和没有他，又有什么差别 数日子过年 在距今已经很久远的那一天，我们就约定好了重逢。我知道，我会找到你。《与之彼端，约定的地方》 人们的思维容易出现定势效应(set effect), 因为人们倾向于利用原有的方式解决问题，且会被困在这个思维里，无法跳出。如果 中途停下来处理其他事情，或中断了原来的情景 ，即使没有带着答案回来，也能在潜意识中明白一点，原来的思维方式可能是错的，或有新的思考方向。 这就是酝酿效应（incubation effect），指将问题搁置在一旁，能使得原有不合适的知识基础的活动性降低（减少思维定势），并采用新的方法考虑或解决问题。 定性，知事，选梦; 遇人，择城，终老。 今天是余生中最年轻的一天，想玩就玩去 爱情也许会过时，但\"爱你\"不会 此为月圆是月缺，彼是月缺为月圆，月圆盼月缺，月缺待月圆。 风起一阵知秋意， 时不时遇见，面对面错过。 三十而立，不是表面的成家或者立业，你立的，是成熟的思维模式，是独立而纵深的思考能力。 寄君一曲，不问曲终人聚散。有说顺其自然？如果有，那是否从此山水不相逢，莫道佳人长与短？ 什么是好工作：一不影响生活作息，二不影响家庭团聚，三能养家糊口。 28岁的你会不会被17岁的你嘲笑 只有当你拿起球拍，只有当你走进球场，你才会真正明白，为什么网球会如此受欢迎；只有当你背着行囊，只有当你远离一方，你才会真正明白，为什么过年如此备受期盼——数日子的日子 数日子的时间很慢，计时间的日子最快。看见的起点在远方，摸不着的终点在想… 活在梦想中 阳光不燥微风正好 我做好了要与你过一辈子的打算，也做好了你随时要走的准备 我却觉得这一大笔积分是我这辈子花的最值一次，因为我得到了钱买不来的东西……希望，从来都无法交易的东西 可否，少些理智，享受一下脱轨的惊喜 真正的离开，是没有告别的 最好的修养，是明知不问 健康大于一切 活得太过自私，想得太过周全，倒想糊涂一世，只在聪明一时，难在取舍","tags":"路由器","url":"https://ghxdghxd.github.io/the-sense.html"},{"title":"MutSigCV的问题","text":"A tab-delimited report of significant mutations, listed in descending order from most significant to least significant. The \"nnei\",\"x\", and \"X\" values in the MutSig output analysis give insight into how the background mutation rate is calculated for a given gene. nnei gives the number of neighboring genes that are pooled together to compute the background mutation rate for that gene; these genes are not necessarily adjacent on the genome, but rather they have nearby covariate values. x gives the number of mutated bases in these neighboring genes that are either silent or non-coding, while X gives the total number of bases related to these neighboring genes. According to the original MutSigCV article, olfactory receptors (ORs) can show up as significant due to the heterogeneity in the mutational processes in cancer (authors' hypothesis)(Lawrence et al. \"Mutational heterogeneity in cancer and the search for new cancer-associted genes\", Nature, 2013). Certain genes, like ORs, can accumulate mutations faster than others, even if their biology is not potentially oncogenic. Therefore, assuming a uniform rate of background mutations/aberrations (GISTIC/JISTIC) is somewhat wrong, no? 肿瘤异质性的突变过程， 一些基因，如ORs，虽然对肿瘤没有功能影响，但因为能够迅速积累突变，而被鉴定出来。","tags":"生信软件","url":"https://ghxdghxd.github.io/MutSigCV.html"},{"title":"CREST的问题","text":"运行CREST时，报错如下错误： Couldn't connect to 192.168.81.177 9000 Connection refused Sorry, the BLAT/iPCR server seems to be down. Please try again later. crest第一步从原始的bam结果中提取出soft-clipped reads，第二步用blat将截短的序列，重新比对回reference。 blat有两种模式，一种是单机版(Stand - alone Blat)，另一种是交互式的客户端/服务器模式(Client/Server Blat)，CREST使用了第二种模式。 这里报这个错误，是因为没有配置好服务器。 配置服务器命令：/share/backup/user/bin/blatSuite-34/gfServer start 192.168.81.177 9000 /path_to_2bit_file/hg19.fa.2bit & （后面的&将此命令放入后台执行） 程序输出Server ready for queries!的提示后，服务器可用。 服务器配置完成后，可以用/share/backup/bin/bin/blatSuite-34/gfClient测试可否连接上服务器。若能正常连接上，则crest可正常运行。","tags":"生信软件","url":"https://ghxdghxd.github.io/CREST.html"},{"title":"人类基因组","text":"参考序列 XY染色体上相同序列 PAR1 PAR2 chrY:10001-2649520 and chrY:59034050-59363566 chrX:60001-2699520 and chrX:154931044-155260560 参考基因组中的多余序列 The chr*_random sequences are unplaced sequence on those reference chromosomes. The chrUn_* sequences are unlocalized sequences where the corresponding reference chromosome has not been determined. 基因结构 1. 基因 ： 表达基因产物的全部DNA序列,包括启动子、5'UTR、开放阅读框(open reading frame，ORF)、外显子、内含子、3'UTR以及调控区 启动子 CAAT框(CAAT box)：其一致顺序为GGCTCAATCT，是真核生物基因常有的调节区，常位于转录起始点上游约-80bp处(或更远处)，可能也是RNA聚合酶的一个结合处，其突变敏感性决定转录效率，但是其突变不影响启动子的特异性。 开放阅读框(open reading frame，ORF)： 在mRNA上从 起始密码子 到 终止密码子 之间的一段序列，该段序列可能编码蛋白质，也可能不编码； 编码区(coding sequences，CDS): CDS是检查cDNA后得到的编码组合序列，能翻译成氨基酸序列的DNA序列，从起始密码子到终止密码子，也就是说CDS与所翻译的氨基酸序列存在严格的3对1的关系； 外显子与内含子分界 每个外显子与内含子的接头部位，都有一高度保守的共有序列，为剪接识别信号，即每个内含子5‘端的两个核苷酸都是 GT ，3‘端的两个核苷酸都是 AG ，这种连接方式称为 GT-AG 法则，是真核细胞中基因表达时剪切内含子和拼接外显子的共同机制。 2. 前信使RNA(precursor messenger RNA, pre-mRNA) 又称heterogeneous nuclear RNA, hnRNA,是转录获得的最原始序列，没有经过任何加工，序列包含从转录起始位点到转录终止位点的全部序列； 3. 信使RNA(mRNA) : 基因转录后加工成熟用于翻译蛋白质的序列，包括CDS序列、3'UTR、5'UTR、5'帽子及3'Poly(A)尾 外显子拼接形成成熟的mRNA，多数基因都有UTR,它们也是外显子拼接的产物，所以，mRNA的长度要大于CDS，只有CDS才编码蛋白，AUG以前的mRNA编码前导序列。 3`UTR的结构 : 3`UTR是PolyA尾巴的载体，而加这个尾巴关键的是PloyA signal。这个信号位点在3`UTR富含T或GT和其上游AATAAA信号中间，大约离AATAAA20-25个核苷酸，这个位点叫Cleavage site。如果AATAAA发生突变，那么PolyA signal就不会被激活。 4. cDNA ：通过mRNA反转录所得，与mRNA序列互补的单链DNA或者与mRNA对应的DNA双链； 5. EST ：表达序列标签，是指从一个随机选择的cDNA 克隆，进行5'端和3'端单一次测序挑选出来获得的短的cDNA部分序列, 代表一个完整基因的一小部分，在数据库中其长度一般从20 到7000bp 不等，平均长度为360 ±120bp。由于cDNA文库的复杂性和测序的随机性，有时多个EST代表同一基因或基因组，将其归类形成EST簇（EST cluster)； 过程|模板|原料|特点|引物 :---:|:---:|:---:|:---:|:---:|:---: DNA复制|双链DNA|四种dNTP|合成的新链与模板链一模一样，半保留复制|需要 转录|双链DNA|四种NTP|合成的新链除了把DNA上的T改为U外，其他一样，半不连续转录|不需要 翻译|mRNA|20种游离的氨基酸|3个碱基决定一个氨基酸|","tags":"理论基础","url":"https://ghxdghxd.github.io/hunman-genome.html"},{"title":"如何根据测序数据计算出数据量以及测序深度？","text":"数据量大小 单端测序 数据量 = reads长度 * reads数 双端测序 数据量 = 单端reads长度 * 单端reads个数 * 2 注： 单位换算 1个碱基=1bp 1kb=1024bp 1M=1024kb 1G=1024M 2.测序深度 测序深度 = 数据量大小 / 参考基因组大小 3.测序与物理覆盖度 在PE测序文库中","tags":"生信数据","url":"https://ghxdghxd.github.io/NGS-coverage.html"},{"title":"登录终端信息","text":"/etc/issue 在终端接口登录时候的提示字符,例如： [ root@linux ~ ] cat /etc/issue CentOS release 5 .6 ( Final ) Kernel \\r on an \\m issue内各代码说明： \\d 本地端时间的日期 \\l 显示第几个终端接口 \\m 显示硬件的等级 \\n 显示主机的网络名称 \\o 显示域名 \\r 操作系统的版本 \\t 显示本地端的时间 \\s 操作系统的名称 \\v 操作系统的版本 /etc/motd 登录后的公告消息, 比如：系统将会在某个时间进行维护 [ root@linux ~ ] vi /etc/motd Hello everyone, Our server will be maintained at please don ' t login at that time,thanks. 那么当用户登录的时候，就会显示设置的内容了。","tags":"系统管理","url":"https://ghxdghxd.github.io/terminal-announcement.html"},{"title":"集群管理笔记","text":"1 服务器管理记录 1.1 清理内存 echo 1 > /proc/sys/vm/drop_caches 1.2 登录显示信息 2 gate mount /dev/sdc1 /extra 3 HPC 3.1 配置 3.1.1 概念 3.1.1.1 物理CPU 实际Server中插槽上的CPU个数 物理cpu数量，可以数不重复的 physical id 有几个 3.1.1.2 逻辑CPU /proc/cpuinfo 用来存储cpu硬件信息， 信息内容分别列出了processor 0 –processor n 的规格。这里需要注意，n是逻辑cpu数 一般情况，我们认为一颗cpu可以有多核，加上intel的超线程技术(HT), 可以在逻辑上再分一倍数量的cpu core出来 逻辑CPU数量 = 物理cpu数量 × cpu cores x 2(如果支持并开启ht) 备注一下：Linux下top查看的CPU也是逻辑CPU个数 3.1.1.3 CPU核数 一块CPU上面能处理数据的芯片组的数量、比如现在的i5 760,是双核心四线程的CPU、而 i5 2250 是四核心四线程的CPU 一般来说，物理CPU个数×每颗核数就应该等于逻辑CPU的个数，如果不相等的话，则表示服务器的CPU支持超线程技术 输入命令cat /proc/cpuinfo 查看物理CPU，physical id有几个；核数，cores有几个；逻辑CPU，processor有几个 3.1.1.4 GPU 1-4节点有GPU， TeslaK20Xm GPU ，cuda核心数 2688， 内存6G， 3.2 rocks cluster 管理 1.rocks run host \"hostname\" #所有节点运行 2.rocks sync config # 同步配制 3. 要先重启管理节点然后计算机节点,否则导致数据不同步 运行 rocks run host \"/etc/init.d/pbs_mom restart\" 即可 4.添加用户 无法qusb要在/etc/group 添加用户 useradd name passwd name usermod -g users name rocks sync users # 可更改/export/home/name 为 /home/name 5.ssh compute-0-* 要输入密码 rm -rf ~/.ssh 然后 退出登录 再登陆 会自动生成新密钥 6.进入单用户模式 在倒计时5秒时，按任意键出现下图， 选择如图，按e进入编辑, 最后加上１,回车,按b,root进入系统 3.3 qmgr qmgr -c \"print server\" # 输出server的属性 qmgr -c \"set server query_other_jobs = true\" # qstat可以查看所有用户 qmgr -c \"set server auto_node_np = True\" # 自动更新节点线程数","tags":"系统管理","url":"https://ghxdghxd.github.io/linux-management.html"},{"title":"FASTQ格式详解","text":"FASTQ 是基于文本的，保存生物序列（通常是核酸序列）和其测序质量信息的标准格式。 其序列以及质量信息都是使用一个ASCII字符标示，最初由Sanger开发，目的是将FASTA序列与质量数据放到一起，目前已经成为高通量测序结果的事实标准。 FASTQ基本格式(reads) 每条reads包括4行： 序列标识以及相关的描述信息，以‘@'开头； 第二行是序列 第三行以‘+'开头，后面是序列标示符、描述信息，或者什么也不加 第四行，是质量信息，和第二行的序列相对应，每一个序列都有一个质量评分，根据评分体系的不同，每个字符的含义表示的数字也不相同。 1 @SEQ_ID 2 GATTTGGGGTTCAAAGCAGTATCGATCAAATAGTAAATCCATTTGTTCAACTCACAGTTT 3 \\+ 4 !''*((((***+))%%%++)(%%%%).1***-+*''))**55CCF>>>>>>CCCCCCC65 Fastq ID illumina测序仪的ID行一般包含测序仪、运行编号、flowcell ID、lane ID、tile ID、横纵轴坐标、索引序列等等 质量信息 质量信息代表一个碱基的错误概率的对数值 Phred quality scores are logarithmically linked to error probabilities Phred $$Q=-10log_{10}P$$ 质量得分与错误概率的对应关系见下表： Phred Quality Score (Q) Probability of incorrect base call Base call accuracy (P) 10 1 in 10 90 % 20 1 in 100 99 % 30 1 in 1000 99.9 % 40 1 in 10000 99.99 % 50 1 in 100000 99.999 % 除了Phred质量得分换算标准，还有就是Solexa标准： $$Q_{solexa-prior to v.1.3}=-10log_{10}\\frac{P}{1-P}$$ 两种换算标准的比较： Relationship between Q and p using the Sanger (red) and Solexa (black) equations (described above). The vertical dotted line indicates p = 0.05, or equivalently, Q ≈ 13. 对于每个碱基的质量编码标示，不同的软件采用不同的方案，目前有5种方案： Sanger，Phred quality score，值的范围从0到92，对应的ASCII码从33到126，但是对于测序数据（raw read data）质量得分通常小于60，序列拼接或者mapping可能用到更大的分数。 Solexa/Illumina 1.0, Solexa/Illumina quality score，值的范围从-5到63，对应的ASCII码从59到126，对于测序数据，得分一般在-5到40之间； Illumina 1.3+， Phred quality score ，值的范围从0到62对应的ASCII码从64到126，低于测序数据，得分在0到40之间； Illumina 1.5+，Phred quality score，但是0到2作为另外的标示， 详见 Illumina 1.8+ SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS..................................................... ..........................XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX...................... ...............................IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...................... .................................**J**JJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJ...................... LLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL.................................................... !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]&#94;_`abcdefghijklmnopqrstuvwxyz{|}~ | | | | | | 33 59 64 73 104 126 S - Sanger Phred+33, raw reads typically (0, 40) X - Solexa Solexa+64, raw reads typically (-5, 40) I - Illumina 1.3+ Phred+64, raw reads typically (0, 40) J - Illumina 1.5+ Phred+64, raw reads typically (3, 40) with 0=unused, 1=unused, 2=Read Segment Quality Control Indicator (bold) (Note: See discussion above). L - Illumina 1.8+ Phred+33, raw reads typically (0, 41) fastq 质量检测工具 fastQC","tags":"生信数据","url":"https://ghxdghxd.github.io/fastq-format.html"},{"title":"R与Rstudio的安装过程（ubuntu）","text":"install R error File failed to load: /extensions/MathZoom.js export CFLAGS = \"-I/share/apps/R_depends/include\" export LDFLAGS = \"-L/share/apps/R_depends/lib\" ./configure ./configure --prefix = /opt/R-3.3.1 --enable-R-shlib --with-libpng --with-jpeglib --with-libtiff --with-x --with-tcltk 1. configure: error: No F77 compiler found sudo apt-get install gfortran 2. configure: error: --with-readline sudo apt-get install libreadline-dev 3. configure: error: --with-x=yes sudo apt-get install libxt-dev 4. checking whether zlib support suffices sudo apt-get install zlib1g-dev 5. checking whether bzip2 support suffices wget <http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz> tar xvf bzip2-1.0.6.tar.gz cd bzip2-1.0.6 sudo make install # OR make -f Makefile-libbz2_so make clean make -n install PREFIX = $R_depends make install PREFIX = $R_depends install bzip2-lib 6. configure: error: \"liblzma sudo apt-get install liblzma-dev 7. configure: error: pcre >= 8.10 wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.39.tar.gz tar xvf pcre-8.39.tar.gz cd pcre-8.39 ./configure --enable-utf8 --prefix = $R_depends make & amp ; sudo make install 8. libcurl >= 7.28.0 library and headers are required with support for https wget https://www.openssl.org/source/openssl-1.1.0b.tar.gz tar xvf openssl-1.1.0b.tar.gz cd openssl-1.1.0b ./config make & amp ; sudo make install wget <https://curl.haxx.se/download/curl-7.50.3.tar.gz> tar xvf curl-7.50.3.tar.gz cd curl-7.50.3 ./configure --with-ssl = /usr/local/ssl/ make & amp ; sudo make install 9.configure: WARNING: you cannot build info or HTML versions of the R manuals sudo apt-get install texinfo 10. configure: WARNING: you cannot build PDF versions of the R manuals, configure: WARNING: you cannot build PDF versions of vignettes and help pages sudo apt-get install texlive 11. configure: WARNING: neither inconsolata.sty nor zi4.sty found: PDF vignettes and package manuals will not be rendered optimally wget <http://mirrors.ctan.org/install/fonts/inconsolata.tds.zip> sudo mv inconsolata.tds.zip /usr/share/texlive/texmf-dist/tex/latex cd /usr/share/texlive/texmf-dist/tex/latex unzip inconsolata.tds.zip sudo mktexlsr 12. 本版本不支持png sudo apt-get install libpng16-dev sudo apt-get install libtiff5-dev make 1./usr/local/lib/libbz2.a: 无法添加符号: 错误的值 rm /usr/local/lib/libbz2.a wget <http://zlib.net/zlib-1.2.8.tar.gz> tar xvf zlib-1.2.8.tar.gz cd zlib-1.2.8 CC = 'gcc -fPIC' ./configure ; make test sudo make install 2./usr/bin/ld: cannot find -lbz2 ; collect2: error: ld returned 1 exit status sudo apt-get install libbz2-dev # 会用到 make CC = 'gcc -fPIC' make install PREFIX = /software/packages make install 1.conftest.c:1:17: fatal error: jni.h cd R-3.3.1/doc wget <https://cran.r-project.org/doc/manuals/r-release/NEWS.pdf> install rstudio sudo apt-get install libjpeg62-dev sudo apt-get install libgstreamer0.10-0 sudo apt-get install libgstreamer-plugins-base0.10-0 export RSTUDIO_WHICH_R = \"/opt/R-3.3.1/bin/R\" 添加到/etc/profile或~/.profile run R Error in grid.Call(L_textBounds, as.graphicsAnnot(xlabel),xlabel),x x, x$y, :无法载入X11字面为2,大小为20的字形- -courier-%s-%s- - -%d- - - - - - - sudo apt-get install t1-xfree86-nonfree ttf-xfree86-nonfree ttf-xfree86-nonfree-syriac sudo apt-get install xfonts-75dpi sudo apt-get install xfonts-100dpi sudo apt-get install mesa-utils sudo apt-get install libxtst-dev using R 无法载入共享目标对象 stringi.so install.packages ( stringi ) R install.packages returns \"failed to create lock directory\" R CMD INSTALL --no-lock & lt ; pkg & gt ; # OR install.packages ( \"Rcpp\" , dependencies = TRUE, INSTALL_opts = c ( '\\--no-lock' )) An irrecoverable exception occurred. R is aborting now ... ERROR: loading failed R CMD INSTALL --no-test-load *packages* nlopt ./configure --enable-shared make make install","tags":"系统管理","url":"https://ghxdghxd.github.io/R-and-Rstudio.html"},{"title":"mount","text":"/etc/fstab 运维都知道的文件，若想把mount的disk和dir设置为每次开机自动加载，那么就要把相关信息写到这个文件中。当用\"mount -a\"命令自动mount的时候，也会去读这个文件。例如： LABEL = /hadoop/9 /hadoop/9 ext3 defaults,noatime,nodiratime,noauto 0 2 LABEL = /hadoop/10 /hadoop/10 ext3 defaults,noatime,nodiratime,noauto 0 2 /etc/mtab 这个文件主要是用mount命令的时候，系统根据实际mount的情况生成的数据，例如： /dev/sdb1 /hadoop/9 ext3 rw,noatime,nodiratime 0 0 /dev/sdc1 /hadoop/10 ext3 rw,noatime,nodiratime 0 0 /proc/mounts 这个文件是/proc/self/mounts的软链接，/proc下面的文件都是保存在内存中的，是内核自动生成的。所以/proc/mounts比/etc/mtab文件能更加真实的反映当前mount的情况 场景应用： 服务器中有一块盘因为有坏道，被umount了，通过\"df -h\"就查看不到这块盘的信息了。 或者你使用\"chmod 000 /dir\",把这块盘设为不能读不能写。 这时如果你管理了1000台服务器，你需要知道你的服务器中哪些盘是被umount了，你会怎么做？ 这里分享一个SHELL脚本，可以给你提供思路： function check_disks { for m in ` awk '$3~/ext3/ {printf\" %s \",$2}' /etc/fstab ` ; do fsdev = \"\" fsdev = ` awk -v m = $m '$2==m {print $1}' /proc/mounts ` ; if [ -z \" $fsdev \" ] ; then msg_ = \" $msg_ $m (u)\" else msg_ = \" $msg_ `awk -v m= $m ' $2 ==m { if ( $4 ~ /&#94;ro,/ ) {printf\" %s ( ro ) \", $2 } ; }' /proc/mounts`\" fi done if [ -z \" $msg_ \" ] ; then echo \"disks ok\" ; exit 0 else echo \" $msg_ \" ; exit 2 fi } 脚本首先通过比较/etc/fstab和/proc/mounts中的不同之处，得到被umount的盘，然后再把ro(read only)的盘也分析出来。","tags":"系统管理","url":"https://ghxdghxd.github.io/mount.html"}]}