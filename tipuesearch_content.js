var tipuesearch = {"pages":[{"title":"About","text":"个人简历","tags":"pages","url":"https://ghxdghxd.github.io/pages/about.html"},{"title":"普通最小二乘法","text":"","tags":"统计建模","url":"https://ghxdghxd.github.io/OLS.html"},{"title":"工具变量(Instrumental variables regression)","text":"","tags":"统计建模","url":"https://ghxdghxd.github.io/IVregression.html"},{"title":"ROC曲线","text":"ROC曲线 接收者操作特征曲线 （receiver operating characteristic curve），简称ROC曲线是一种坐标图式的分析工具，用于： 选择最佳的信号侦测模型、舍弃次佳的模型 在同一模型中设定最佳阈值 ROC分析的是二元分类模型（如阳性/阳性，有病/没病）： ROC空间 ROC空间将伪阳性率（FPR）定义为 X 轴，真阳性率（TPR）定义为 Y 轴。 TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。 TPR=TP/(TP+FN) FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。 FPR=FP/(FP+TN)","tags":"统计建模","url":"https://ghxdghxd.github.io/ROC.html"},{"title":"git submodule的用法","text":"常用命令 git clone <repository> --recursive #递归的方式克隆整个项目 git submodule add projectB.git projectB #添加子模块 git submodule init #初始化子模块 git submodule update #更新子模块 git submodule foreach git pull #拉取所有子模块 如何使用 1. 创建带子模块的版本库 例如我们要创建如下结构的项目 project | --moduleA | --readme.txt 创建project版本库，并提交readme.txt文件 git init --bare project.git git clone project.git project1cd project1 echo \"This is a project.\" > readme.txt git add . git commit -m \"add readme.txt\" git push origin master cd .. 创建moduleA版本库，并提交a.txt文件 git init --bare moduleA.git git clone moduleA.git moduleA1 cd moduleA1 echo \"This is a submodule.\" > a.txt git add . git commit -m \"add a.txt\" git push origin master cd .. 在project项目中引入子模块moduleA，并提交子模块信息 cd project1 git submodule add ../moduleA.git moduleA git status git diff git add . git commit -m \"add submodule\" git push origin master cd .. 使用git status可以看到多了两个需要提交的文件，其中.gitmodules指定submodule的主要信息，包括子模块的路径和地址信息，moduleA指定了子模块的commit id，使用git diff可以看到这两项的内容。这里需要指出父项目的git并不会记录submodule的文件变动，它是按照commit id指定submodule的git header，所以.gitmodules和moduleA这两项是需要提交到父项目的远程仓库的。 On branch master Your branch is up-to-datewith 'origin/master' . Changes to be committed: ( use \"git reset HEAD ...\" to unstage ) new file: .gitmodules new file: moduleA 2. 克隆带子模块的版本库 方法一，先clone父项目，再初始化submodule，最后更新submodule，初始化只需要做一次，之后每次只需要直接update就可以了，需要注意submodule默认是不在任何分支上的，它指向父项目存储的submodule commit id。 git clone project.git project2 cd project2 git submodule init git submodule update cd .. 方法二，采用递归参数--recursive，需要注意同样submodule默认是不在任何分支上的，它指向父项目存储的submodule commit id。 git clone project.git project3 --recursive git submodule update --init --recursive 3. 修改子模块 修改子模块之后只对子模块的版本库产生影响，对父项目的版本库不会产生任何影响，如果父项目需要用到最新的子模块代码，我们需要更新父项目中submodule commit id，默认的我们使用git status就可以看到父项目中submodule commit id已经改变了，我们只需要再次提交就可以了。 cd project1/moduleA git branch echo \"This is a submodule.\" > b.txt git add . git commit -m \"add b.txt\" git push origin master cd .. git status git diff git add . git commit -m \"update submodule add b.txt\" git push origin master cd .. 4. 更新子模块 更新子模块的时候要注意子模块的分支默认不是master。 方法一，先pull父项目，然后执行 git submodule update ，注意moduleA的分支始终不是master。 cd project2 git pull git submodule update cd .. 方法二，先进入子模块，然后切换到需要的分支，这里是master分支，然后对子模块pull，这种方法会改变子模块的分支。 cd project3/moduleA git checkout master cd .. git submodule foreach git pull cd .. 5. 删除子模块 网上有好多用的是下面这种方法 git rm --cached moduleA rm -rf moduleA rm .gitmodules vim .git/config 删除submodule相关的内容，例如下面的内容 [ submodule \"moduleA\" ] url = /Users/nick/dev/nick-doc/testGitSubmodule/moduleA.git 然后提交到远程服务器 git add . git commit -m \"remove submodule\" 但是我自己本地实验的时候，发现用下面的方式也可以，服务器记录的是.gitmodules和moduleA，本地只要用git的删除命令删除moduleA，再用git status查看状态就会发现.gitmodules和moduleA这两项都已经改变了，至于.git/config，仍会记录submodule信息，但是本地使用也没发现有什么影响，如果重新从服务器克隆则.git/config中不会有submodule信息。 git rm moduleA git status git commit -m \"remove submodule\" git push origin master","tags":"工具集","url":"https://ghxdghxd.github.io/git-submodule.html"},{"title":"meta Analysis","text":"metafor document An Overview of Functions in the metafor Package Viechtbauer gesis ma with metafor meta-analysis from odds ratios and confidence intervals using metafor dm <- structure ( list ( or = c ( 1.6 , 4.4 , 1.14 , 1.3 , 4.5 ), cill = c ( 1.2 , 2.9 , 0.45 , 0.6 , 3.2 ), ciul = c ( 2 , 6.9 , 2.86 , 2.7 , 6.1 )), . Names = c ( \"or\" , \"cill\" , \"ciul\" ), class = \"data.frame\" , row.names = c ( NA , -5L )) dm $ logor <- log ( dm $ or ) dm $ se1 <- ( log ( dm $ ciul ) - dm $ logor ) / 1.96 dm $ se2 <- ( dm $ logor - log ( dm $ cill )) / 1.96 dm $ se <- ( dm $ se1 + dm $ se2 ) / 2 library ( metafor ) dmres <- rma.uni ( yi = logor , sei = se , data = dm ) pdf () forest ( dmres , atransf = exp , showweights = T , mlab = \"rsid\" , slab = paste0 ( \"study\" , 1 : 5 )) dev.off ()","tags":"统计建模","url":"https://ghxdghxd.github.io/meta.html"},{"title":"archlinux安装与配置","text":"archlinux安装 # u盘启动后 # 连接网络 wifi-memu mount /dev/sda1 /mnt mkdir -p /mnt/home mount /dev/sda2 /mnt/home # 修改中国镜像源,如163.com vi /ect/pacman.d/mirrorlist pacstrap -i /mnt base base-devel #生成挂载文件fstab genfstab -U /mnt >> /mnt/etc/fstab archlinux 初步配置 #切换到archlinux arch-chroot /mnt /bin/bash 本地语言 vi /etc/locale.gen en_US.UTF-8 UTF-8 zh_CN.UTF-8 UTF-8 #生效 locale-gen echo LANG = en_US.UTF-8 > /etc/locale.conf 时区 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # 或 # 按提示选择时区 tzselect #设置硬件时间 hwclock --systohc --utc grub引导系统 # 支持grub和EFI，可只选grup pacman -S grub efibootmgr grub-install --target = i386-pc --recheck --debug /dev/sda grup-mkconfig -o /boot/grub/grub.cfg 主机名 echo Garch >> /etc/hostname 网络配置 # 有线 systemctl enable dhcpcd.service # 无线 pacman -S iw wpa_supplicant dialog archlinux 配置 # 最小安装 # X桌面 pacman -S xorg-server # 显卡驱动 pacman -S xf86-video-ati pacman -S gnome gnome-tweak-tool pacman -S ttf-ubuntu # 可选","tags":"系统管理","url":"https://ghxdghxd.github.io/archlinux.html"},{"title":"docker安装与配置","text":"docker centos yum install docker tee /etc/yum.repos.d/docker.repo <<-'EOF' [dockerrepo] name=Docker Repository baseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/ enabled=1 gpgcheck=1 gpgkey=https://yum.dockerproject.org/gpg EOF sed -i 's/other_args=\\\"\\\"/other_args=\\\"--graph=\\/share\\/apps\\/docker\\\"/g' /etc/sysconfig/docker for i in ` seq 1 8 ` ; do sudo scp /etc/yum.repos.d/docker.repo compute-0- $i :/etc/yum.repos.d/docker.repo done rocks run host \"yum install docker-engine\" rocks run host \"sed -i 's/other_args=\\\"\\\"/other_args=\\\"--graph=\\/share\\/apps\\/docker\\\"/g' /etc/sysconfig/docker\" 手动安装 # 手动安装centos6.5 一些需要安装 yum remove docker-engine cd /share/apps/until/docker/ yum install ./lua-filesystem-1.4.2-1.el6.x86_64.rpm yum install ./lxc-libs-1.0.11-1.el6.x86_64.rpm yum install ./lua-lxc-1.0.11-1.el6.x86_64.rpm yum install ./lua-alt-getopt-0.7.0-1.el6.noarch.rpm yum install ./lxc-1.0.11-1.el6.x86_64.rpm yum install ./docker-io-1.7.1-2.el6.x86_64.rpm wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo yum install device-mapper-event-libs service docker restart 安装错误 # 下面错误： /usr/bin/docker: relocation error: /usr/bin/docker: symbol dm_task_get_info_with_deferred_remove, version Base not defined in file libdevmapper.so.1.02 with link time reference fix: $ sudo yum install device-mapper-event-libs # 如果无法安装，重新更新 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo # 然后再安装 docker应用 启动docker service docker start 添加用户 # 添加docker group： sudo groupadd docker # 将当前用户添加到docker组： sudo gpasswd -a ${ USER } docker # 重启docker服务： sudo service docker restart # 开机启动 chkconfig docker on 修改镜像和容器的存放路径 # /etc/sysconfig/docker加入： other_args = \"--graph=/data/docker\" # 停止Docker服务 service docker stop # 备份数据到新的存放路径 cp -rf /var/lib/docker /data/ # 修改备份/var/lib/docker路径 mv /var/lib/docker { ,.bak } # 启动Docker服务 service docker start # 测试Docker服务 docker info 用法 查看镜像 docker images 查找镜像 docker search 查看容器 docker ps -a 运行容器 docker run 将宿主机的/var/data挂载到容器中的/data: docker run -tdi -v /var/data:/data centos 如果ls: cannot open directory '.': Permission denied 修改/etc/sysconfig/docker，OPTIONS去掉--selinux-enabled","tags":"系统管理","url":"https://ghxdghxd.github.io/docker.html"},{"title":"网球拍的平衡点","text":"网球拍平衡点测量 ps95 长69宽26.5 tour95 长68.5宽26 这个是每份点得出来的公式（pts点，inch英寸） 1pts = 1/8 inch = 1/8 * 2.54cm = 0.3175cm 下面以标准拍子27英寸长度为例，换算出是68.5cm，那中心点就是34.25cm。然后假设你所量出平衡点到拍底的距离为h。 如果大于34.25，则是（h-34.25）/0.3175=T，就是T点头重 如果小于34.25，则是（34.25-h）/0.3175=T，就是T点头轻 图中可知，此时拍子是完全平衡状态，只需测量纸片到底盖的距离就可以了，按这个方法测量出我的拍子是32.34cm，套用公式: （34.25-32.34）÷0.3175=6.015，也就是6点头轻了！ 另附上球拍头轻和头重的优劣: 头轻拍更灵活易于控制，能让选手在网前有不错的表现，但是不能提供足够大的力量。头重拍，灵活性差，但能提供额外的力量更有利于底线的击球。一般专业的球拍都是头轻拍或者是平衡拍，因为这样更利于网前技术的发挥，而且专业球员都有很好的身体素质可以自身去发力。而初学拍比较多的是头重拍，这样能使初学者并不需要太多的发力就能击出力量较大的球。","tags":"兴趣爱好","url":"https://ghxdghxd.github.io/tennis-racquet.html"},{"title":"mpileup格式","text":"mpileup mpileup 结果中的 >, <; 代表reference skip, 基因组上没有的序列， the reference position is bridged by reference skip. 计算depth要减去reference skip数目","tags":"理论基础","url":"https://ghxdghxd.github.io/mpileup.html"},{"title":"循环肿瘤DNA","text":"循环肿瘤DNA，英文叫：circulating tumor DNA，简称ctDNA。 对ctDNA进行测序，是目前很火的LiquidBiopsy（液体活检）中的一种。 在今天的讲解当中，我们会主要参考Nature Medicine杂志，在2014年4月刊登的AaronNewman（下称：Aaron）等人写的一篇文章。 这篇文章的题目是：《An ultrasensitive method for quantitatingcirculating tumor DNA with broad patient coverage》，同时，我们也会结合国内一些服务公司的实际操作方法，来介绍ctDNA测序。 Aaron给他们的实验方法起了一个专有名词：CAncer PersonalizedProfiling by deep SEQuencing，简称：CAPP- Seq。 意义 首先，我们来说一下ctDNA测序的临床意义。 1.减少病人的开刀痛苦，只要抽血，不必开刀，就可以做检测。 2.增加可检测的病人范围，对于不适合做开刀手术的病人。例如，已经发生肿瘤全身转移的病人。也可以用测ctDNA的方法来测肿瘤的基因突变。 3.只抽血（而不必开刀），所以取样很方便。所以它可以应用于肿瘤病人的病情随访，并可以多次取样。 原理 正常细胞和肿瘤细胞都会破裂，细胞破裂之后，细胞中的DNA就会被释放到体液当中去。其中进入血液的这部分DNA，就称为血液游离DNA。那么，它也被称作血浆游离DNA，或者cell free DNA，简称cfDNA。 这些DNA片段的长度，主要集中在100BP~240BP之间，大部分在170BP左右，把血液当中游离的DNA抽提出来，建成DNA测序的文库。用探针杂交、或者PCR扩增等方法，把其中与肿瘤相关的DNA富集出来，进行高通量测序。 然后再进行数据分析，看哪些基因有突变。接着根据基因突变的信息，来决定下一步的治疗方法 这就是ctDNA测序的核心原理。 难点 从原理上，ctDNA测序，简单易懂，但是在实际的操作过程当中，需要克服一系列的技术难点。 第一个难点，是在全部的血浆游离DNA当中，ctDNA只占很小的一部分，大约只有万分之几到千分之几。其余的，都是正常细胞的DNA。一般而言，肿瘤早期，ctDNA占全部游离DNA的比例会更低一些，到肿瘤晚期，ctDNA占全部游离DNA的比例会高一些。但是要检测到千分之几、万分之几的突变，总是一件困难的事情 第二个难点，是血液当中的游离DNA量很少，大约每一毫升的血浆当中，只会有十几纳克（ng）的游离DNA。通过比较好的、专用的DNA抽提试剂盒，从一毫升的血浆当中，大约可以抽提到10&#94;-9个纳克（ng，10&#94;-9）左右的游离DNA，每一个正常的、人的细胞，大约含有3.3个皮克(pg，10&#94;-12)的基因组DNA。也就是说1个ng的基因组DNA，相当于来源于300个细胞的DNA量。 目前国内做ctDNA测序的科研实践当中，一般是一次抽10个毫升的血，从中可以分离到约5到6毫升的血浆。从这5~6毫升的血浆当中，可以抽提到约 50ng~60ng 的游离DNA。60个ng的DNA，大约相当于来自18000个细胞的基因组DNA。 综合上面所说，ctDNA 测序的两大难点： 第一，是突变信号相对于背景信号来说，信号强度极低，只有万分之几，到千分之几。 第二，是样本量极其有限，必须在几十个ng的游离DNA当中，找到突变信息。 实验设计 所以，在整个 ctDNA 测序的实践过程当中，所有的实验步骤，都是围绕上述2个难点，来进行设计的。 首先，我们来说采血。 如果采血完成后，马上可以分离血浆，并抽提游离DNA，那么可以用常规的枸橼酸钠、或者EDTA抗凝采血管来采血。但是，不要用肝素采血管来进行采血，因为肝素是多种DNA修饰酶的强抑制剂，而后面的DNA建库过程当中，要用到多种DNA修饰酶，所以不要用肝素采血管来进行采血。 如果另一种情况，血液要经过一段时间的保存、运输后，才能达到中央实验室，进行血浆分离，并抽提游离DNA的话，那么建议采用 Streck 公司出品的专用的采血管来进行抽血。Streck 的采血管有以下两个特点： 第1，它可以防止血液当中的游离DNA降解 第2，它可以防止血液当中的白细胞破裂 因为血液当中的游离DNA很少，而白细胞很多，如果白细胞破裂，那会大大增加测序当中的本底值，所以，防止白细胞破裂是非常必要的。 第二步，是抽提血浆游离DNA。在Aaron的文章当中，是用Qiagen公司出的QIAamp Circulating Nucleic Acid Kit来进行DNA抽提的。这是一个专门用来抽提血浆游离DNA的专用试剂盒。 第三步，是用抽提好的DNA来构建文库。在 Aaron 的文章当中，是用 KAPA 公司的出的 KAPA Library Preparation Kit 来进行文库构建的。 第四步，是用捕获试剂盒来对文库进行杂交捕获。在 Aaron 的文章当中，是设计了一个针对139个肿瘤相关基因的捕获 Panel。这个 Panel 的覆盖范围是125个KB的大小。 在这个 Panel 当中，包括按照 hg19 参考基因组序列，设计目标区域。这些区域可以用于检测点突变、和插入缺失突变。同时，对于 ALK 和 ROS1 这两个基因当中，常见的、易发生融合基因突变的突变位点，也设计了相应的捕获探针，目的是可以更好地检测到融合基因突变。 捕获探针是请 Roche 公司旗下的 Nimblegen 公司合成的。 第五步，捕获好的文库，用高保真聚合酶进行扩增。Aaron 的文章当中，是用 KAPA 公司的KAPA HiFi Hot Start Ready Mix 酶，配合Illumina公司的文库接头，进行文库的PCR扩增。然后用 Qiagen 公司的 QIAquick PCR Purification Kit，对 PCR 扩增产物进行纯化。 第六步，扩增好的文库，用 HiSeq 2000 测序仪，进行读长为双端各100碱基的高通量DNA测序，这里要特别说明一下，ctDNA 的测序深度是非常深的。一般情况下，会测到上万倍、甚至几万倍的测序深度。在Aaron 的文章当中，平均每个ctDNA 样本，是测2.1G的数据。也就是说，测序的数据量，相当于捕获目标区域大小的17000倍。 第七步，是把测序得到的序列，进行生物信息学分析。在ctDNA的数据分析当中，有一些与传统的捕获测序分析过程不一样的参数设定。 第一点，就是去除 duplicaton 的过滤条件是不一样的。所谓duplication，就是因为上机测序前的 PCR 扩增，导致一个原始的模板复制出许多个拷贝来。这些复制出来的拷贝，被测序过程多次测到，这就叫 duplication。因为 ctDNA 的测序深度很深，达到上万倍，所以会有大量的 duplication。在 Aaron 的文章当中，duplication 的比例，会高达50%~70%。也就是说，每10个读到的序列当中，有5个到7个是重复的。 传统的测序分析当中，如果2条序列的起始位置、和结束位置都一样，就判定这2个序列是 duplication。但是，在 Aaron 的方法当中，如果两条序列的起始、和结束位置是一样的，但是，其中有一个碱基的差别（SNV），则不认为这两条序列是 duplication。这样做，可以尽可能地保留测序结果当中，测到的序列的多样性。也就保证了检测的灵敏度。 第二点，是判定点突变（SNV），Aaron采用的置信条件，与通常的方法也不同。Aaron 一定要这个突变的碱基的测序的质量值（Phred quality score）高于30，才确定这个突变是一个真的突变（SNV），测序得到的碱基质量值（Phred quality score）是测序仪的分析程序，对一个碱基的可信度的通用判定标准。如果这个值高于30，则这个碱基读错的可能性，低于千分之一，Aaron 通过设置这样一个置信条件，来减少因为测序误差，可能带来的误判。这样，也就提高了检测分析结果的特异性。 这就是 ctDNA 测序检测的方法。 结果 介绍完方法，我们接下来介绍 Aaron的实验结果。 Aaron 检测了13个非小细胞肺癌病人的35份游离 DNA 样本，和5个正常人的游离 DNA 样本。 同时，也检测了病人的肿瘤样本、和germline 样本（外周血白细胞DNA），把测序的结果进行数据分析。以肿瘤样本中检测到的突变为阳性标准，画出 ROC 曲线。 这里，我们简单介绍一下 ROC 曲线，ROC 曲线的英文是: Receiver Operating Characteristic (ROC)，ROC的横轴，是100%减掉特异性得到的值，纵轴是敏感性的值。 ROC 曲线越靠近图型的左上角，则这个检测的较果越好，它的灵敏性、和特异性都好。反之，ROC 曲线越接近对角线，则检测的效果越差，会有很多的假阴性、和假阳性。 ROC 曲线下方部分的面积，占整个座标矩型面积的比例，叫 AUC 值，Area Under Curve (AUC)。AUC 值的取值范围在：0.5-1之间。越接近1，则这个检测的分辨效果越好，越接近0.5，则分辨效果越差。 AUC 值是评判一个方法好坏的重要标准。 更多介绍 ROC 曲线的内容，有兴趣同学可以在微信公众号【陈巍学基因】当中，回复\"ROC\"三个字，就可以看到更详细的介绍了。 回到 Aaron 的实验结果，我们来看这条蓝色的曲线，这是全部13个病人的结果。可以看到这条曲线是比较接近图的左上角的，它的 AUC 值，达到了0.95。 这13个病人当中，包括了4个癌症 I 期的病人，和9个癌症 II 期到 IV 期的病人，如果只看这9个癌症II 期到 IV 期的病人的结果（红色曲线），AUC值达到0.99。 这两个数值，0.95和0.99的 AUC 值，都说明：CAPP-seq 是一个相当好的检测肿瘤基因突变的方法。 在 Aaron 的文章当中，对肿瘤的体积与 CAPP-seq 方法检测到的突变的数量，也进行了分析。共9个病人进行了 CT 或者 PET-CT的检测。 来看肿瘤的体积大小，并同时做 CAPP-seq 的检测。检测的结果如果所示，肿瘤的体积，与每毫升血液中检测到的突变量数，呈现出十分明显的相关性。R&#94;2值达到0.89，P值达到0.0002。 结论 文章的数据表明：针对游离 DNA 进行高深度的靶向DNA 测序，会是未来一个很有前景的肿瘤临床基因检测手段。","tags":"理论基础","url":"https://ghxdghxd.github.io/ctDNA.html"},{"title":"质量值体系","text":"质量值体系 相比之前培训时所学的质控内容, (我拿到的) 流程中还多了一步 phred33to64 , 也就是把 .fastq 格式的数据从 Phred33 质量值体系转换为 Phred64 质量体系, 于是先补充学习了下质量值体系: 首先\b要从质量值说起, 测序仪器下机数据的 fastq 文件中, 每条序列都对应了相同长度的质量值, 反映出每个碱基的准确性和可靠性, (现在主流用的) 计算公式为: Q = -10log10p 而这个 p 值就是 Phred 计算出来的, 表示一个碱基被识别错误的可能性, Phred 一开始是一个软件 (或者说计算方法), 对测序仪器识别到的荧光强度 (三代的不了解) 进行评估, 针对不同仪器有不同的标准表, 然后根据表中荧光强度的范围和\b\b分辨率分析得出碱基的 p 值, 由于比较可靠, 逐渐被各大公司采纳 (以上脑补翻译自 Phred quality score 和 Phred base calling ) 反正, Q 值为 10 就表示这个碱基有 90% 的概率是正确的, 20 就是 99%, 40 就是 4 个 9, 很好记, 相信大家也都很熟悉 但是这时候问题就来了, 因为一个碱基对应一个质量值, 可 Q 值可以是一位数也可以是两位数, 连在一起的话就分不出哪个对应哪个碱基 (比如某两个碱基的质量值序列为 123 , 则可能为 1|23 或 12 | 3, 当然这是个极端的例子), 此外也浪费\b存储空间, 因为一个数字只有 10 种可能性, 却要占去一个字符位, 而一个字节有 8 位, 理论上已经可以代表 256 种状态, 这还没换算一个字符要占多少字节, 因此就会把碱基质量值转换为相应的 ASCII 码, 这是计算机中最基本的一套字符体系, 用来把常用符号 (共 127 个) 转为二进制以便于机器使用, ASCII 码表见 ASCII code chart , 这样一个字符就可以搞定了, 很方便很省事 但是这时候问题又来了, 最理想的情况当然是直接把质量值作为序号找出对应的那个 ASCII 码, 比如质量值为 40 就换成十进制 40 对应的 ASCII 码,可惜质量值根据测序仪公司的标准\b不同, 范围也各不相同, 基本都包括了 0 至 40 的区间, 甚至还可能是负值, 这就没法愉快地玩耍了, 而且人家 ASCII 码表也不配合, 0 到 31 对应的都是些控制字符 (比如回车, 退格), 根本不适合打印和保存, 可打印的都得从 32 号排起 (参见 ASCII printable code chart ), 所以各家测序仪器公司就把质量值再加上某个固定值作为 ASCII 码转换成了可打印字符从而保存在 FASTQ 文件中 可是问题还没有完, 这个固定值是多少好呢, 各家公司是竞争对手, 怎么可能你用什么我也用什么, 所以 Sanger 公司加了 33, 也就是质量值为 0 就转换成 ASCII 码 33, 查表可知为 ! , 也即从可打印的字符开始 (排除了空格), 这就是现在所谓的 Phred33 体系, 当时的 Solexa (后来被 Illumina 收购) 公司就偏不用 33 (此处为个人脑补), 偏要加个 64, 这样质量值为 0 就用 @ 表示, 后面从 1 开始的就依次对应了 ABCD, 于是就成了 Phred64 体系, 至于当时三巨头的另一家测序仪公司 454 Life Sciences (后被 Roche 收购) 就更绝, 人家从碱基开始就不用 ACTG 表示, 直接整了个 ColorSpace 体系出来, 根本不和你们玩, (话说 Color Space 这玩意儿曾经把我狠狠地坑了好久), 当然后来大家也不跟 454 玩了, 最后他也就没得玩了 回到质量值体系, 这样就由 Sanger 公司和 Illumina 公司产生了 Phred33 体系和 Phred64 体系, 两家互相拗着, 这就\b辛苦了写生物信息分析软件的人, 两种质量体系都要考虑, 当然好一点的软件都是有参数接受体系类型的, 更好一点的软件就会自动判断体系类型进行对应转换 本来就这样结束的话也算是个圆满的故事了, 可是\b墨菲他老人家不高兴了 ( Murphy's law ), 所以在 2011 年, Illumina 公司表示他们又要改成 Phred33 体系了 ( Upcoming changes in CASAVA ), 真是大(wo)快(le)人(ge)心(qu)啊! 这么来回一折腾, 结果还是回到了最初的起点, 与老基友相拥而泣了, Phred33 一统江湖! (当然实际上现在 Ilumina 的 Phred33 和最初 Sanger 的 Phred33 还是有点区别的, 详见后文) 扯了这么多, 发现写了半天才刚交代完故事背景, 剩下的部分就等有空再写了, 最后上点干货: 先是 wikipedia 上非常直观的示例, 可以看出各家公司各个版本的质量值体系 SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS..................................................... ..........................XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX...................... ...............................IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...................... .................................JJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJ...................... LLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL.................................................... ! \"# $ %&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]&#94;_`abcdefghijklmnopqrstuvwxyz{|}~ | | | | | | 33 59 64 73 104 126 0........................26...31.......40 -5....0........9.............................40 0........9.............................40 3.....9.............................40 0.2......................26...31........41 S - Sanger Phred+33, raw reads typically (0, 40) X - Solexa Solexa+64, raw reads typically (-5, 40) I - Illumina 1.3+ Phred+64, raw reads typically (0, 40) J - Illumina 1.5+ Phred+64, raw reads typically (3, 40) with 0=unused, 1=unused, 2=Read Segment Quality Control Indicator (bold) (Note: See discussion above). L - Illumina 1.8+ Phred+33, raw reads typically (0, 41) 然后光看也没什么用啊, 就[有人写了个小函数](http://onetipperday.blogspot.com.br/2012/10/code-snip- to-decide-phred-encoding-of.html), 用来分析 fastq 文件 (压缩或未压缩均可), 代码如下: fqtype () { less $1 | head -n 999 | awk '{if(NR%4==0) printf(\" %s \", $0 );}' \\ | od -A n -t u1 -v \\ | awk 'BEGIN{min=100;max=0;}\\ {for(i=1;i<=NF;i++) {if( $i >max) max= $i ; if( $i <min) min= $i ;}}END\\ {if(max<=74 && min<59) print \" Phred+33 \"; \\ else if(max>73 && min>=64) print \" Phred+64 \"; \\ else if(min>=59 && min<64 && max>73) print \" Solexa+64 \"; \\ else print \" Unknown score encoding \"; \\ print \" ( \" min \" , \" max, \" ) \";}' } 写在 shell 配置文件里, source 然后 fqtype <fastq_file> 就行了, 这个代码有点老, 还没加 [35, 75] 的判断, 我又懒得重新改判断逻辑, 所以直接在最后加了个打印最小值最大值, 再跟上面的示例一比, 就基本确定是什么体系了 关于这两种体系对我们实际流程的影响和分析, 请听下回分解 转自： http://not.farbox.com/post/phred_p1 感觉写的很好理解，特此谢谢。","tags":"理论基础","url":"https://ghxdghxd.github.io/phred.html"},{"title":"终端显示颜色","text":"echo显示带颜色，需要使用参数-e 格式如下: echo -e \"\\033[字背景颜色;文字颜色m字符串\\033[0m\" 例如: echo -e \"\\033[41;37m TonyZhang \\033[0m\" 其中41的位置代表底色, 37的位置是代表字的颜色 注： 1、字背景颜色和文字颜色之间是英文的\"\"\"\" 2、文字颜色后面有个m 3、字符串前后可以没有空格，如果有的话，输出也是同样有空格 下面看几个例子： echo -e \"\\033[30m 黑色字 \\033[0m\" echo -e \"\\033[31m 红色字 \\033[0m\" echo -e \"\\033[32m 绿色字 \\033[0m\" echo -e \"\\033[33m 黄色字 \\033[0m\" echo -e \"\\033[34m 蓝色字 \\033[0m\" echo -e \"\\033[35m 紫色字 \\033[0m\" echo -e \"\\033[36m 天蓝字 \\033[0m\" echo -e \"\\033[37m 白色字 \\033[0m\" echo -e \"\\033[40;37m 黑底白字 \\033[0m\" echo -e \"\\033[41;37m 红底白字 \\033[0m\" echo -e \"\\033[42;37m 绿底白字 \\033[0m\" echo -e \"\\033[43;37m 黄底白字 \\033[0m\" echo -e \"\\033[44;37m 蓝底白字 \\033[0m\" echo -e \"\\033[45;37m 紫底白字 \\033[0m\" echo -e \"\\033[46;37m 天蓝底白字 \\033[0m\" echo -e \"\\033[47;30m 白底黑字 \\033[0m\" 控制选项说明 ： 代码 作用 \\33[0m 关闭所有属性 \\33[1m 设置高亮度 \\33[4m 下划线 \\33[5m 闪烁 \\33[7m 反显 \\33[8m 消隐 \\33[30m -- \\33[37m 设置前景色 \\33[40m -- \\33[47m 设置背景色 \\33[nA 光标上移n行 \\33[nB 光标下移n行 \\33[nC 光标右移n行 \\33[nD 光标左移n行 \\33[y;xH 设置光标位置 \\33[2J 清屏 \\33[K 清除从光标到行尾的内容 \\33[s 保存光标位置 \\33[u 恢复光标位置 \\33[?25l 隐藏光标 \\33[?25h 显示光标","tags":"系统管理","url":"https://ghxdghxd.github.io/terminal-color.html"},{"title":"BRCA基因检测","text":"背景 一方面，BRCA是抑癌基因，突变后容易得肿瘤，另一方面，BRCA可以修复DNA损伤。而DNA两条自我修复途径： PARP(poly ADP-ribose polymerase)是DNA修复酶作为关键因子 BRCA1和BRCA2起关键作用 如果上述修复通路同时锁定，肿瘤细胞会因累积DNA损伤而死亡，因此 如果BRCA突变，则可用PARP抑制剂治疗肿瘤 BRCA体细胞突变检测现况 在乳腺癌、卵巢癌中检测到的BRCA 1/2 突变，其中20%左右是由于体突变引起。体细胞突变的检测需要正常组织做对照，常用血细胞做对照（如TCGA 癌症研究）。研究发现，体细胞突变与胚系突变的卵巢癌，乳腺癌病人在生存、预后方面没有明显的差异，并且都可以用奥拉帕利进行治疗。但是相对于胚系突变，体细胞突变检测难度大些。检测的难度和准确性主要受样本类型、癌症细胞含量以及突变比例（具有BRCA 1/2 体细胞突变的癌细胞占所有癌细胞的比例）等影响。因此，针对BRCA基因体细胞突变的检测技术还在完善中。","tags":"理论基础","url":"https://ghxdghxd.github.io/BRCA.html"},{"title":"hotnet2","text":"hotnet2是一种新型计算机算法，能够筛选庞大的遗传数据，发现相互作用基因，而这些基因一旦突变就会导致多种癌症的发生发展。 背景 预先定义一个合理的基因集合或组合的统计需求 标准化分析突变相关通路及蛋白复合物的方法 这项研究没有选择癌症遗传学研究，而是采用了与众不同的方式，寻找癌症样品中频繁出现的单个基因的突变。基因并不会常常独自作战，主要还是与其它基因形成网络和途径，调控细胞功能。在某些情况下，途径中多个基因中出现一个突变，就会引发故障发生，导致癌症。因为有害突变可以分布在多个这样的基因网络，因此难以通过统计检验发现它们。 而Hotnet2运算方法则能在网络水平上分析基因，帮助科学家们识别罕见，但又重要的癌症突变。 HotNet2 算法是通过将病患突变数据投射到一张基因相互作用图谱上，然后寻找比偶发突变更常见的突变之间的相互作用网络，这一程序能作为heat sources寻找经常突变的基因。通过分析图谱上分布和聚集的方式，HotNet2 能找到与癌症相关的的\"热\"网络。 Hotnet 的最初版本已经被用于识别急性髓细胞白血病、卵巢癌和几个其它类型癌症中的重要网络，目前这一版本也经过修改，可以用于处理更大和更复杂的泛癌症数据集。 subnetworks.json结构 stats : {Minimum edge weight δ: { Minimum subnetwork size1 : {expected : XXX, observed : XXX, pval : XXX} Minimum subnetwork size2 : { expected : XXX, observed : XXX, pval : XXX} }} deltas : [ deltas1, deltas2, deltas3, deltas4] Minimum edge weight δ mutation_matrices : {deltas 1:{}, deltas2 : {}, deltas3 : {}, deltas4 : {}} 基因不同位点的类型（snv indel 或 cnv) typeToSamples subnetworks：{deltas :[ network0, network1] } network: {edges :{ ks Minimum subnetwork size sampleToTypes： 样本类型","tags":"生信软件","url":"https://ghxdghxd.github.io/hotnet2.html"},{"title":"git的一般用法","text":"Git用法 1 建立仓库 远程 git remote add origin git@github.com:ghxdghxd $NAME .git 本地(初始化) git init 2 常用操作 拉取 git pull origin master 提交 git add *.py git commit -m \"message\" git push origin master/dev/develop 重命令与删除 git rm git mv 3 分支操作 主支 修补 发布 开发 功能 master hotfix release develop feature git branch /-a/r # 查看本地/全部/远程分支 git branch [ name ] # 建立分支 git branch -d [ name ] # 删除本地分支 git push origin --delete [ name ] # 删除远程分支 git checkout -b [ name ] origin/develop # 建立并切换开发分支 git checkout [ name ] # 切换分支 git merge --no-ff [ name ] # 合并分支 git push origin dev:develop # 本地分支提交到远程 # 删除远程分支后，本地未同步的问题 git remote show origin # 可以查看remote地址，远程分支，还有本地分支与之相对应关系等信息 git remote prune origin # 删除了那些远程仓库不存在的分支 push命令用于将本地分支的更新，推送到远程主机。 git push <远程主机名> <本地分支名>:<远程分支名> git pull类似: git pull <远程分支>:<本地分支> 注意，分支推送顺序的写法是<来源地>:<目的地>， 所以git pull是<远程分支>:<本地分支>，而git push是<本地分支>:<远程分支>。 如果省略远程分支名，则表示将本地分支推送与之存在\"追踪关系\"的远程分支(通常两者同名)，如果该远程分支不存在，则会被新建。 git push origin master 上面命令表示，将本地的master分支推送到origin主机的master分支。如果后者不存在，则会被新建。 如果省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支。 git push origin :master 等同于 git push origin --delete master 上面命令表示删除origin主机的master分支。 如果当前分支与远程分支之间存在追踪关系，则本地分支和远程分支都可以省略。 git push origin 上面命令表示，将当前分支推送到origin主机的对应分支。 如果当前分支只有一个追踪分支，那么主机名都可以省略。 git push 如果当前分支与多个主机存在追踪关系，则可以使用-u选项指定一个默认主机，这样后面就可以不加任何参数使用git push。 git push -u origin master 上面命令将本地的master分支推送到origin主机，同时指定origin为默认主机，后面就可以不加任何参数使用git push了。 不带任何参数的git push，默认只推送当前分支，这叫做simple方式。此外，还有一种matching方式，会推送所有有对应的远程分支的本地分支。Git 2.0版本之前，默认采用matching方法，现在改为默认采用simple方式。如果要修改这个设置，可以采用git config命令。 git config --global push.default matching 或者 git config --global push.default simple 还有一种情况，就是不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用–all选项。 git push --all origin 上面命令表示，将所有本地分支都推送到origin主机。 如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做git pull合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用–force选项。 git push --force origin 上面命令使用–force选项，结果导致在远程主机产生一个\"非直进式\"的合并(non-fast-forward merge)。除非你很确定要这样做，否则应该尽量避免使用–force选项。 最后，git push不会推送标签(tag)，除非使用–tags选项。 git push origin --tags 中文乱码 git config --global core.quotepath false core.quotepath设为false的话，就不会对0x80以上的字符进行quote。中文显示正常。 gitignore忽略文件 1、配置语法： 以斜杠\"/\"开头表示目录； 以星号\"*\"通配多个字符； 以问号\"?\"通配单个字符 以方括号\"[]\"包含单个字符的匹配列表； 以叹号\"!\"表示不忽略(跟踪)匹配到的文件或目录； 此外，git 对于 .ignore 配置文件是按行从上到下进行规则匹配的，意味着如果前面的规则匹配的范围更大，则后面的规则将不会生效； 2、示例： （1）规则：fd1/* 说明：忽略目录 fd1 下的全部内容；注意，不管是根目录下的 /fd1/ 目录，还是某个子目录 /child/fd1/ 目录，都会被忽略； （2）规则：/fd1/* 说明：忽略根目录下的 /fd1/ 目录的全部内容； （3）规则： /* !.gitignore !/fw/bin/ !/fw/sf/ 说明：忽略全部内容，但是不忽略 .gitignore 文件、根目录下的 /fw/bin/ 和 /fw/sf/ 目录； warning: LF will be replaced by CRLF 在Windows环境下使用git进行add的时候，会提示如下warning: \"warning:LF will be replacee by CRLF\"。 这是因为在Windows中的换行符为CRLF，而在Linux中的换行符为LF。 在git创建的项目中换行符为LF，而执行git add时，系统会提示LF将被转换为CRLF。 解决的办法很简单，禁止git的自动转换即可。 git config --global core.autocrlf false //禁用自动转换","tags":"工具集","url":"https://ghxdghxd.github.io/git.html"},{"title":"变异标准化","text":"介绍 VCF(Variant Call Format)格式文件是一种灵活的格式, 可以用来表示SNPs、INDELs及CNVs等很多种变异类型.但, VCF文件中的变异表达在参考型和突变型的表示上具有不唯一性 ，一次失败的识别很容易造成错误的分析. 变异标准化(variant normalization)，不仅适用于双等位基因同时适用于多等位基因. 定义 VCF中的变异标准化涉及两个方面: 变异长度上的简约性(parsimony) 变异位置左对齐(left alignment) 1、简约性(Parsimony) 在变异表达中，简约性代表用 尽可能少但不为0的核苷酸数量 来表示每一个等位基因，它描述了变异的长度属性， 定义： 当且仅当一个变异使用了尽可能少的核苷酸, 并且没有一个等位基因的长度为0时, 称该变异为简约的. 并定义： 如果每个等位基因的最左侧核苷酸相同, 且移除该核苷酸并不会导致空等位基因, 则称该变异在左侧有多余核苷酸. 例 ：如下实例中, 多核苷酸多态性在前三种表示上都有多余核苷酸, 而第四种表示上则是简约的. 当一个变异在左侧具有多余核苷酸时, 称该变异为左侧未简约, 并需要进行左切除. 同理, 右侧未简约也需要进行由切除. 简约性在INDELs一样体现, 在左对齐章节将做示范. 图中展示了多核苷酸多态性的多种展示, 最左列 用颜色区分了四种可能存在的不同表示方式. 右边一列 展示了在VCF文件中的相应表示. 最后一列 展示了四种方式的简约性表现. 在简约性的定义的基础上, 容易看到: 如果一个变异是非简约的, 则所有的等位基因长度必须大于1. 2、左对齐(Left alignment) 将一个变异左对齐表示将该变异的起始位置尽可能地向左移动. 这是插入、缺失中的相关概念, 描述了变异的位置属性. 为了区分左对齐和简单的对一个变异左填充, 给出 定义 如下: 在保持所有等位基因长度的前提下, 当且仅当一个变异不可能再往左移动时, 称该变异为左对齐的. 下图展示了一个没有标准化的短串联重复序列(一种特殊的indel). 并且用和图中颜色对应的文字对变异进行描述. VCF文件要求任意一个等位基因都不能以空字符串的形式表示(空等位基因).红色的indel是非法的VCF表示方式. 绿色的变异并不是左对齐的, 你可以在该变异的每个等位基因左边加上一个核苷酸,并移除每个等位基因右边的C. 但该变异是简约的. 橙色的变异是左对齐的, 但是右侧并不简约 蓝色的变异是左对齐的, 但是左侧并不简约.褐红色的变异是左对齐并且简约的. 褐红色的变异是左对齐并且简约的 图中展示了CA微卫星(Short Tendem Repeat)的多种表示方式, 最左列 用颜色区分了五种可能存在的不同表示方式. 右边一列 展示了在VCF文件中的相应表示. 最后一列 展示了该微卫星的五种方式的左对齐以及简约性表现. 3、区分是否标准化 当且仅当一个变异是简约且左对齐时, 称该变异是标准化的. 3.1、引论 为了检测一个变异是否标准化, 我们首先需要证明以下引论(1): 当且仅当变异是非左对齐或者非右简约时, 该变异的所有等位基因都以同样的核苷酸结尾. 从=>方向证明: 如果一个indel是左对齐并且右侧简约时, 该变异的所有等位基因不以同样的核苷酸结尾. 首先假设一个indel已经左对齐并且右侧简约. 1.当任一等位基因长度大于1时, 由于该indel是右侧简约的, 很显然每个等位基因不能以同样的核苷酸结尾. 2.当其中某一等位基因长度为1时, 并假设所有的等位基因都以A结尾. 此时, 为了避免出现空等位基因的情况, 右侧已经不再能去除相同的A核苷酸,故右侧仍然是简约的. 3.在任意等位基因左侧延长一个核苷酸(复制参考基因组), 此时在右侧就出现了多余的核苷酸. 将该核苷酸去除,结果导致indel的每个等位基因在保持长度不变的前提下向左移动了一个位置, 这和该indel是左对齐矛盾. 因此, 所有的等位基因都不能以相同的核苷酸结尾. 从<=方向证明: 如果一个indel是非左对齐或者非右简约时, 该变异的所有等位基因都以同样的核苷酸结尾. 假设该变异是非左对齐的, 则对该变异进行左对齐操作时, 为了保证长度不变, 则每移动一个核苷酸就必须从右侧移除一个相同的核苷酸, 因此该变异右侧至少存在一个相同的核苷酸, 否则无法进行左对齐操作. 假设该变异是非右简约的, 根据定义可知, 该变异的所有等位基因中, 最右侧的碱基都必须相同以期望被移除. 3.2、必然性 一个变异是标准化的当且仅当: 1.在左侧没有多余的碱基; 2.任意一个等位基因都以不同的核苷酸结尾; 证明: 一个变异是标准化的当且仅当该变异简约并且左对齐 => 一个变异是标准化的当且仅当该变异左简约并且右简约并且左对齐 => 一个变异是标准化的当且仅当该变异左侧没有多余核苷酸并且右侧没有多余核苷酸并且左对齐 => 一个变异是标准化的当且仅当该变异左侧没有多余的核苷酸并且所有等位基因不以相同的核苷酸结尾 (引论1) 3.3、唯一性 变异的标准化得到唯一的变异表达是非常重要的, 在我们证明之前, 先凭直觉接受: 一个变异的任意表达都可以通过同时在等位基因一端添加参考核苷酸或者同时在等位基因的一端移除相同的核苷酸, 从而得到另外一种表达. 现在假设有变异的两个标准化A和B. 不失一般性, 假设B在A的右侧, 由于标准化的定义, A和B都是左对齐的, 如果A和B不在同一个位置则意味着B可以通过向左对齐变成A(由于A和B表示了相同的变异), 与B是标准化矛盾, 所以A和B必然在相同的位置. 假设A和B虽然在同一个位置, 但是长度不同, 不失一般性认为B比A长, 则B肯定是非简约并且可以通过去除核苷酸达到和A相同的长度, 与B标准化矛盾, 所以A和B长度必然相同. 由于A和B必然在同一个位置并且长度相同, 故变异的标准化表示是唯一的. 3.4、 实施 vt中已经得到了实施. 3.5、标准化的算法 现在我们知道了如何区分一个变异是否标准化, 我们只需要操作变异表达方式, 直到最后侧的核苷酸不同并且去除左侧多余的核苷酸, 即可得到一个标准化后的变异表达. 标准化双等位基因和多等位基因的算法表示如下: 1到8行进行了左对齐操作并且保证右侧简约. 9到11行保证左侧的简约. 4、比较 2014年5月20号 下面的表格展示了对一个不公开数据进行标准化时, 正确标准化的变异数量. 该比较在2014年5月20号完成. Dataset bcftools gatk vt comments normalized 18849 18794 18849 bcftools的标准化存在bug, 会去除不同的核苷酸. normalized after bcftools 0 0 0 bcftools的标准化结果没有被进一步标准化 normalized after gatk - 0 57 gatk的写了只使用双等位基因的文档. 57个gatk的标准化结果被vt重新左对齐.其中有6个是双等位基因, 51个是多等位基因. 注意有两个变异被gatk修改但是没有完全标准化 normalized after vt - 0 0 vt的标准化结果没有被进一步标准化 使用的命令为: bcftools norm -f ref.fa in.vcf -O z > out.vcf.gz java -jar GenomeAnalysisTK.jar -T LeftAlignAndTrimVariants --trimAlleles -R ref.fa --variant in.vcf.gz -o out.vcf.gz vt normalize -r ref.vcf.gz -o out.vcf.gz 使用的版本为: bcftools v0.2.0-rc8-5-g0e06231 ( using htslib 0 .2.0-rc8-6-gd49dfa6 ) GATK v3.1-1-g07a4bf8 vt normalize v0.5 5、一个该标准化算法失效的例子 我们用下面的规则区分变异的标准化(normalization)和分解/组合(decomposition/reconstruction): 标准化代表着将一个变异的多个表达降低为一个权威的表达. 标准化可以适用于双等位基因和多等位基因. 变异标准化\u0014问题已经被解决, 并且有一个唯一的表示方式(左对齐并且简约的表达). 数学证明已经发表.1 变异的分解代表着将一个变异的表达拆分成多个变异. 这个分解可以是纵向的 —— 将一个多等位基因分解成双等位基因. 也可以是横向的 —— 将一个包含多个indel和snp群的复合变异分解成多个单一变异. 横向分解常常不仅有一个结果. 相似地, 将多个变异组合重构成一个变异也有横向和纵向两种方式. 讲一个复合变异纵向分解是一个多对一的函数, 将多个双等位基因组合为一个复合变异则并不具有唯一解, 需要考虑到所有等位基因可能的排列. 如果你的例子中包含了变异的分解和组合, 那么你就有可能发现前后不一致. 区分标准化和分解组合的不同点是非常重要的. 标准化的概念意味着变异有标准表示格式. 如果在你的标准化概念里加入分解和组合, 由于可辨别性的内在差异(是否具有唯一解等), 你将会得到前后不一致的情况. 当进行分解组合操作时, 我认为应当考虑以下几点: 你的变异仅仅用来表示单个个体还是一个群体？ 这些基因型是否在独立的阶段产生? 在不同的情况下可能得到不同的答案. An example of inconsistent variant representation due to using vt normalize","tags":"理论基础","url":"https://ghxdghxd.github.io/variant.html"},{"title":"markdown格式详解","text":"1 概述 Wiki: Markdown Markdown 是一种轻量级标记语言，创始人为约翰·格鲁伯（John Gruber）。 它使用易读易写的纯文本格式编写文档，然后转换成有效的 XHTML（或者 HTML）文档。 这种语言吸收了很多在电子邮件中已有的纯文本标记的特性。 \".md\" 和 \".markdown\" 都是被普遍支持的扩展名，不过 \".md\" 更加简单和方便。 为什么选择 Markdown 它基于纯文本，方便修改和共享 几乎可以在所有的文本编辑器中编写 有众多编程语言的实现，以及应用的相关扩展 在 GitHub 等网站中有很好的应用 很容易转换为 HTML 文档或其他格式 适合用来编写文档、记录笔记、撰写文章 兼容 HTML Markdown 完全兼容 HTML 语法，可以直接在 Markdown 文档中插入 HTML 内容： < table > < tr > < td > 1 </ td > < td > 2 </ td > </ tr > < tr > < td > 3 </ td > < td > 4 </ td > </ tr > </ table > 这段代码会变成下面的样子： 1 2 3 4 2 语法 2.1 标题 任何数量的\"=\"和\"-\" 使用左边或两边对称\"#\" 显示效果 正副二级标题 标记1-6级标题 一级标题 ====== # 一级标题 # 一级标题 二级标题 ------ ## 二级标题 ## 二级标题 ### 三级标题 ### 三级标题 #### 四级标题 #### 四级标题 ##### 五级标题 ##### 五级标题 ###### 六级标题 ##### 六级标题 2.2 段落与换行 段落的前后必须是空行： 空行指的是行内什么都没有，或者只有空白符（空格或制表符） 相邻两行文本，如果中间没有空行会显示在一行中（换行符被转换为空格） 如果需要在段落内加入换行（ <br> ）： 可以在前一行的末尾加入至少两个空格, 然后换行写其它的文字 Markdown 中的多数区块都需要在两个空行之间 2.3 引用 2.3.1 引用内容 在段落或其他内容前使用 > 符号，就可以将这段内容标记为 '引用' 的内容（ <blockquote> ）： >引用内容 引用内容 2.3.2 多行引用 >多行引用 >可以在每行前加 `>` 多行引用 可以在每行前加 > >如果仅在第一行使用 `>`， 后面相邻的行即使省略 `>`，也会变成引用内容 如果仅在第一行使用 > ， 后面相邻的行即使省略 > ，也会变成引用内容 >如果引用内容需要换行， >可以在行尾添加两个空格 > >或者在引用内容中加一个空行 如果引用内容需要换行， 可以在行尾添加两个空格 或者在引用内容中加一个空行 2.3.3 嵌套引用 >也可以在引用中 >>使用嵌套的引用 也可以在引用中 使用嵌套的引用 2.3.4 其他 Markdown >在引用中可以使用使用其他任何 *Markdown* 语法 在引用中可以使用使用其他任何 Markdown 语法 2.4 列表 2.4.1 无序列表 * 可以使用 `*` 作为标记 + 也可以使用 `+` - 或者 `-` * 可以使用 * 作为标记 + 也可以使用 + - 或者 - 2.4.2 有序列表 1. 有序列表以数字和 `.` 开始； 3. 数字的序列并不会影响生成的列表序列； 4. 但仍然推荐按照自然顺序（1.2.3...）编写。 1.有序列表以数字和 . 开始； 3.数字的序列并不会影响生成的列表序列； 4.但仍然推荐按照自然顺序（1.2.3...）编写。 2.4.3 嵌套的列表 1. 第一层 + 1-1 + 1-2 2. 无序列表和有序列表可以随意相互嵌套 1. 2-1 2. 2-2 1.第一层 +1-1 +1-2 2.无序列表和有序列表可以随意相互嵌套 1.2-1 2.2-2 语法和用法 无序列表项的开始是：符号 空格； 有序列表项的开始是：数字 . 空格； 空格至少为一个，多个空格将被解析为一个； 如果仅需要在行前显示数字和 . ： 05\\. 可以使用：数字\\. 来取消显示为列表 05. 可以使用：数字\\. 来取消显示为列表 \\* 的语法专门用来显示 Markdown 语法中使用的特殊字符，参考 字符转义 2.5 代码 2.5.1 代码块 可以使用缩进来插入代码块： // Tab开头 Markdown // 四个空格开头 代码块前后需要有至少一个空行，且每行代码前需要有至少一个 Tab 或四个空格； 2.5.2 行内代码 也可以通过 ``，插入行内代码（` 是 Tab 键上边、数字 1 键左侧的那个按键）： 例如 <title>Markdown</title> 2.5.3 转换规则 代码块中的文本（包括 Markdown 语法）都会显示为原始内容，而特殊字符会被转换为 HTML 字符实体 。 2.6 分隔线 1. 可以在一行中使用三个或更多的 * 、 - 或 _ 来添加分隔线： *** ------ ___ 2. 多个字符之间可以有空格（空白符），但不能有其他字符： * * * - - - 2.7 超链接 2.7.1 行内式 格式为 [link text](URL 'title text') 。 ① 普通链接： [Google](http://www.google.com/) Google ② 指向本地文件的链接： [icon.png](./images/icon.png) icon.png ③ 包含 'title' 的链接: [Google](http://www.google.com/ \"Google\") Google title 使用 ' 或 \" 都是可以的。 2.7.2 参考式 参考式链接的写法相当于行内式拆分成两部分，并通过一个 识别符 来连接两部分。参考式能尽量保持文章结构的简单，也方便统一管理 URL。 ① 首先，定义链接： [Google][link] Google 第二个方括号内为链接独有的 识别符 ，可以是字母、数字、空白或标点符号。识别符是 不区分大小写 的； ② 然后定义链接内容： [link]: http://www.google.com/ \"Google\" 其格式为： [识别符]: URL 'title' 。 其中，URL可以使用 <> 包括起来，title 可以使用 \"\"、''、() 包括（考虑到兼容性，建议使用引号），title 部分也可以换行来写； 链接内容的定义可以放在同一个文件的 任意位置 ； ③ 也可以省略 识别符 ，使用链接文本作为 识别符 ： [Google][] [Google]: http://www.google.com/ \"Google\" Google 参考式相对于行内式有一个明显的优点，就是可以在多个不同的位置引用同一个 URL。 2.7.3 自动链接 使用 <> 包括的 URL 或邮箱地址会被自动转换为超链接： <http://www.google.com/> <123@email.com> http://www.google.com/ 123@email.com 该方式适合行内较短的链接，会使用 URL 作为链接文字。邮箱地址会自动编码，以逃避抓取机器人。 2.8 图像 插入图片的语法和插入超链接的语法基本一致，只是在最前面多一个 ! 。也分为行内式和参考式两种。 2.8.1 行内式 ![GitHub](https://avatars2.githubusercontent.com/u/3265208?v=3&s=100 \"GitHub,Social Coding\") 方括号中的部分是图片的替代文本，括号中的 'title' 部分和链接一样，是可选的。 2.8.2 参考式 ![GitHub][github] [github]: https://avatars2.githubusercontent.com/u/3265208?v=3&s=100 \"GitHub,Social Coding\" 2.8.3 指定图片的显示大小 Markdown 不支持指定图片的显示大小，不过可以通过直接插入 <img /> 标签来指定相关属性： < img src = \"https://avatars2.githubusercontent.com/u/3265208?v=3&s=100\" alt = \"GitHub\" title = \"GitHub,Social Coding\" width = \"50\" height = \"50\" /> 2.9 强调 1. 使用 * * 或 _ _ 包括的文本会被转换为 <em></em> ，通常表现为斜体： 这是用来 *演示* 的 _文本_ 这是用来 演示 的 文本 2. 使用 ** ** 或 __ __ 包括的文本会被转换为 <strong></strong> ，通常表现为加粗： 这是用来 **演示** 的 __文本__ 这是用来 演示 的 文本 3. 用来包括文本的 * 或 _ 内侧不能有空白，否则 * 和 _ 将不会被转换（不同的实现会有不同的表现）： 这是用来 * 演示* 的 _文本 _ 这是用来 * 演示* 的 _文本 _ 4. 如果需要在文本中显示成对的 * 或 _ ，可以在符号前加入 \\ 即可： 这是用来 \\*演示\\* 的 \\_文本\\_ 这是用来 *演示* 的 _文本_ 5. * 、 ** 、 _ 和 __ 都必须 成对使用 。 2.10 字符转义 反斜线（ \\ ）用于插入在 Markdown 语法中有特殊作用的字符。 这是用来 *演示* 的 _文本_ 这是用来 \\*演示\\* 的 \\_文本\\_ 这是用来 演示 的 文本 这是用来 *演示* 的 _文本_ 这些字符包括： \\ ` * _ {} [] () # + - . !","tags":"理论基础","url":"https://ghxdghxd.github.io/markdown.html"},{"title":"R","text":"R的常用命令 R 动态生成变量，并赋值， assign ( x , value )","tags":"工具集","url":"https://ghxdghxd.github.io/R.html"},{"title":"计算机字符编码","text":"计算机系统通用的字符编码 数据结构(字符) 在计算机内存中，统一使用Unicode编码；当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。 用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件： ![编码1]](../images/bianma-1.png) utf-8编码的文件在内存中是unicode编码显示 浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器： 服务器把动态生成的Unicode内容转换为UTF-8再传输 所以你看到很多网页的源码上会有类似 的信息，表示该网页正是用的UTF-8编码。（UTF-8编码没有字节序的问题） 字符转化 序列化 : 将一个数据结构（unicode编码， utf-8等）转化为二进制的数据流。用于存储，或者发送给网络中的其它程序。 不同的编码形成的二进制流不一样。 反序列化 ：与序列化相反，将二进制流重新恢复成更易于处理和阅读的数据结构 python中的编码 Python中一切都是对象（object）。 与字符编码类型有关的对象有str和bytes。 str对象存储的字符是UNICODE类型，bytes对象存储的字符就是一串byte。 str u'字符串以u开头' str.encode后得到的是一个bytes对象 bytes b'字节以b开头' bytes.decode之后，得到的是一个str对象。 decode的作用是将其他编码的字符串转换成unicode编码，如str1.decode('gb2312')，表示将gb2312编码的字符串str1转换成unicode编码","tags":"工具集","url":"https://ghxdghxd.github.io/Unicode.html"},{"title":"pandas","text":"常用 read_csv pd . read_csv ( file , sep = \" \\t \" , header = None ) # 第一行不设为列名 bed_df = pd . read_table ( file , dtype = 'object' , name = [ 'chr' , 'start' , 'pos' , 'ref' , 'alt' ]) cat 合并 Series ([ 'a' , 'b' , 'c' ]) . str . cat ([ 'A' , 'B' , 'C' ], sep = ',' ) filter mat[mat.index.map(lambda x:x in list)] dataframe to list mat.drop_duplicates().values.tolist() merge dataframe pd.connect([mat1, mat2, mat3], axis=1) #axis=1 cbind, asis=0 rbind insert mat.insert(0, 'date', date) # insert in 0 col pandas错误 read_csv: C-engine CParserError: Error tokenizing data When using read_csv like this: df = pd . read_pickle ( 'faulty_row.pkl' ) df . to_csv ( 'faulty_row.csv' , encoding = 'utf8' , index = False ) df . read_csv ( 'faulty_row.csv' , encoding = 'utf8' ) You get the following exception: CParserError: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file. Solution 1 You can read the CSV using the python engine then no exception is thrown: df . read_csv ( 'faulty_row.csv' , encoding = 'utf8' , engine = 'python' ) Solution 2 If your second-to-last line includes an '\\r' break. You can open in universal-new-line mode to solve the error. pd . read_csv ( open ( 'test.csv' , 'rU' ), encoding = 'utf-8' , engine = 'c' )","tags":"工具集","url":"https://ghxdghxd.github.io/pandas.html"},{"title":"python","text":"python优化 做一个pythonic的人 1. 枚举 for i , item in enumerate ( iterable ): print i , item 2. python -m cProfile 3. time -p bash test.sh/python test.py","tags":"工具集","url":"https://ghxdghxd.github.io/python.html"},{"title":"shell","text":"常用命令 0表示标准输入 1表示标准输出 2表示标准错误输出 > 默认为标准输出重定向，与 1 > 相同 2 > & 1 意思是把 标准错误输出 重定向到 标准输出. & >file 意思是把 标准输出 和 标准错误输出 都重定向到文件file中 awk $0 ~/aaa/表示0包括aaa split ( string, array, field separator ) split ( string, array ) \\- - & gt ; 如果第三个参数没有提供，awk就默认使用当前FS值。 substr ( s,p ) 返回字符串s中从p开始的后缀部分 substr ( s,p,n ) 返回字符串s中从p开始长度为n的后缀部分 length函数返回整个记录中的字符数。 gsub ( regular expression, subsitution string, target string ) ; index ( a,b ) , r返回b中a的位置，没有返回0 for ( i = 1 ; i & lt ; = length ( a ) ; i++ ) awk,getline,用于获得下一行 输出奇数， seq 10 | awk '{print $0;getline}' 1 3 5 7 9 输出偶数 seq 10 | awk '{getline;print $0}' 2 4 6 8 10 输出三行,如果后面没有足够的行，则输出最后一行 seq 10 | awk '{getline;getline;print $0}' 3 6 9 10 sed sed -n '/A/,/B/p' 匹配A的行与匹配B的行之间的内容 sed -n '2p,4,5p' 输出2 4 ,5 行 grep cat file | grep '[:space:]*#' 匹配空格 grep -P '\\t' 匹配制表符 grep -E \"abc|123\" myfile -n 两个关键词 ln ln -s 源文件 目标文件 paste paste -s -d '\\t' 多行合并成一行 tr tr -s ' ' 多个空格变一个 sort sort -V 按染色体排序 1 ，2，3，，，，X，Y unzip unzip -l zipfile 查看list unzip -p zipfile \"*/getfile\" | less 查看指定文件 unzip -d outdir 指定输出目录 gzip gzip -t/--test 检测gz文件是否有错误 计算 expr expr 1 + 1 expr 查看网速sar sar -n DEV 1 100 sudo !!命令 没有特定输入sudo命令而运行，将给出没有权限的错误。那么，你不需要重写整个命令，仅仅输入'!!'就可以抓取最后的命令。 Ctrl+x+e命令 这个命令对于管理员和开发者非常有用。为了使每天的任务自动化，管理员需要通过输入vi、vim、nano等打开编辑器。 仅仅从命令行快速的敲击\"Ctrl-x-e\"，就可以在编辑器中开始工作了。 nl命令 \"nl命令\"添加文件的行数。 shuf n1 随机从一个文件或文件夹中选择行/文件/文件夹。首先使用ls命令来显示文件夹的内容。 数组 array =( ` cat test.txt | cut -f 1 ` ) ${ array [@] } # 数组全部 ${# array [@] } # 数组长度 ${ array [0] } # 数组元素 0 1 2","tags":"工具集","url":"https://ghxdghxd.github.io/shell.html"},{"title":"算法复杂度","text":"原文章在 这里 图例 绝佳 不错 一般 不佳 糟糕 数据结构操作 数据结构 时间复杂度 空间复杂度 平均 最差 最差 访问 搜索 插入 删除 访问 搜索 插入 删除 Array O(1) O(n) O(n) O(n) O(1) O(n) O(n) O(n) O(n) Stack O(n) O(n) O(1) O(1) O(n) O(n) O(1) O(1) O(n) Singly-Linked List O(n) O(n) O(1) O(1) O(n) O(n) O(1) O(1) O(n) Doubly-Linked List O(n) O(n) O(1) O(1) O(n) O(n) O(1) O(1) O(n) Skip List O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) O(n) O(n) O(n) O(n log(n)) Hash Table - O(1) O(1) O(1) - O(n) O(n) O(n) O(n) Binary Search Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) O(n) O(n) O(n) O(n) Cartesian Tree - O(log(n)) O(log(n)) O(log(n)) - O(n) O(n) O(n) O(n) B-Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) Red-Black Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) Splay Tree - O(log(n)) O(log(n)) O(log(n)) - O(log(n)) O(log(n)) O(log(n)) O(n) AVL Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) 图操作 节点 / 边界管理 存储 增加顶点 增加边界 移除顶点 移除边界 查询 Adjacency list O(|V|+|E|) O(1) O(1) O(|V| + |E|) O(|E|) O(|V|) Incidence list O(|V|+|E|) O(1) O(1) O(|E|) O(|E|) O(|E|) Adjacency matrix O(|V|&#94;2) O(|V|&#94;2) O(1) O(|V|&#94;2) O(1) O(1) Incidence matrix O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|E|) 堆操作 类型 时间复杂度 Heapify 查找最大值 分离最大值 提升键 插入 删除 合并 Linked List (sorted) - O(1) O(1) O(n) O(n) O(1) O(m+n) Linked List (unsorted) - O(n) O(n) O(1) O(1) O(1) O(1) Binary Heap O(n) O(1) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(m+n) Binomial Heap - O(1) O(log(n)) O(log(n)) O(1) O(log(n)) O(log(n)) Fibonacci Heap - O(1) O(log(n)) O(1) O(1) O(log(n)) O(1) 大 O 复杂度图表","tags":"Coding","url":"https://ghxdghxd.github.io/timeO.html"},{"title":"Java parallelGCThreads的选择","text":"1.含义 ParallelGCThreads，表示JVM在进行并行GC的时候，用于GC的线程数，-XX:ParallelGCThreads=43，表示配置GC线程数为43。 2.JVM相关接口 JVM中，关于ParallelGCThreads的计算代码如下： unsigned int VM_Version :: calc_parallel_worker_threads () { unsigned int result ; if ( is_M_series ()) { // for now, use same gc thread calculation for M-series as for niagara-plus // in future, we may want to tweak parameters for nof_parallel_worker_thread result = nof_parallel_worker_threads ( 5 , 16 , 8 ); } else if ( is_niagara_plus ()) { result = nof_parallel_worker_threads ( 5 , 16 , 8 ); } else { result = nof_parallel_worker_threads ( 5 , 8 , 8 ); } return result ; } unsigned int Abstract_VM_Version :: parallel_worker_threads () { if (! _parallel_worker_threads_initialized ) { if ( FLAG_IS_DEFAULT ( ParallelGCThreads )) { _parallel_worker_threads = VM_Version :: calc_parallel_worker_threads (); } else { _parallel_worker_threads = ParallelGCThreads ; } _parallel_worker_threads_initialized = true ; } return _parallel_worker_threads ; } unsigned int Abstract_VM_Version :: calc_parallel_worker_threads () { return nof_parallel_worker_threads ( 5 , 8 , 8 ); } unsigned int Abstract_VM_Version :: nof_parallel_worker_threads ( unsigned int num , unsigned int den , unsigned int switch_pt ) { if ( FLAG_IS_DEFAULT ( ParallelGCThreads )) { assert ( ParallelGCThreads == 0 , \"Default ParallelGCThreads is not 0\" ); // For very large machines, there are diminishing returns // for large numbers of worker threads. Instead of // hogging the whole system, use a fraction of the workers for every // processor after the first 8. For example, on a 72 cpu machine // and a chosen fraction of 5/8 // use 8 + (72 - 8) * (5/8) == 48 worker threads. unsigned int ncpus = ( unsigned int ) os :: active_processor_count (); return ( ncpus <= switch_pt ) ? ncpus : ( switch_pt + (( ncpus - switch_pt ) * num ) / den ); } else { return ParallelGCThreads ; } } 3.计算方法 上面列出了与ParallelGCThreads计算相关的几个核心接口，其中，最主要关注nof_parallel_worker_threads接口，该接口中给出了计算ParallelGCThreads值的具体算法，具体如下： ① 如果用户显示指定了ParallelGCThreads，则使用用户指定的值。 ② 否则，需要根据实际的CPU所能够支持的线程数来计算ParallelGCThreads的值，计算方法见步骤③和步骤④。 ③ 如果物理CPU所能够支持线程数小于8，则ParallelGCThreads的值为CPU所支持的线程数。这里的阀值为8，是因为JVM中调用nof_parallel_worker_threads接口所传入的switch_pt的值均为8。 ④ 如果物理CPU所能够支持线程数大于8，则ParallelGCThreads的值为8加上一个调整值，调整值的计算方式为：物理CPU所支持的线程数减去8所得值的5/8或者5/16，JVM会根据实际的情况来选择具体是乘以5/8还是5/16。 比如，在64线程的x86 CPU上，如果用户未指定ParallelGCThreads的值，则默认的计算方式为：ParallelGCThreads = 8 + (64 - 8) * (5/8) = 8 + 35 = 43。","tags":"工具集","url":"https://ghxdghxd.github.io/Java-parallelGCThreads.html"},{"title":"QQplot","text":"QQplot Q-Q plot 即Quantile-Quantile Plot。它在各类研究中经常用到，主要是直观的表示观测值与预测值之间的差异。 在SPSS中很容做，Analysis - Descriptive statistics - Q-Qplot。 Q-Q plot主要是用来估计数量性状观测值与预测值之间的差异。一般我们所取得的数量性状数据都为正态分布数据。在GWAS研究中Q-Q plot的X和Y轴主要是代表各个SNP的-lg P values。预测的线是一条从原点发出的45°角的虚线。实际观测值则是标的实心点。 Q-Q plot主要要点： 预测的虚线为什么是45°出来的呢？因为预测的线实际是通过在QQ图中第一象限作图得出。理论上一个点A在该图上的位置应该是A预测值=A实际值，转化为坐标就是A（x，y）x=y。所以预测的线是一条从原点发出的45°线。 观测值的点的坐标是怎么得出来的。同样设点A的坐标是（x，y）x为预测值，y为实际观测值。查了一下R 中qq plot的算法是这样的 pvals <- read.table ( \"DGI_chr3_pvals.txt\" , header = T ) observed <- sort ( pvals $ PVAL ) lobs <- - ( log10 ( observed )) expected <- c ( 1 : length ( observed )) lexp <- - ( log10 ( expected / ( length ( expected ) +1 ))) 具体解释是这样的，先把P值从小到大排序。lobs代表纵坐标，lexp代表横坐标，纵坐标就是观测P值的- log10，而横坐标则根据P值数目而定。比如，当只有3个P值 P1=0.0001 P2=0.001 P3=0.01，那么在这个P值组中，length(observed)=3，对于P1=0.0001 expected=1 lexp=-log10（1/3+1），对于P2=0.001 expected=2 lexp=-log10（2/3+1）， P3=0.01 expected=3 lexp=-log10（3/3+1）。。。。。依此类推。 如果出现了偏离的情况说明实际值跟预测值有偏差，在GWAS研究中，那个SNP点出现了较大的偏离，则认为这个SNP位点的观测值的偏离是由这个SNP突变所产生的遗传作用造成的","tags":"理论基础","url":"https://ghxdghxd.github.io/QQplot.html"},{"title":"cfDNA,ctDNA,CTC","text":"肿瘤的近亲--cfDNA,ctDNA,CTC 全称循环游离DNA（Circulating free DNA），是指存在于循环血中的DNA片段。cfDNA可以来源于凋亡、坏死的细胞释放释放的DNA片段；细胞以囊泡的形式分泌到循环血中的DNA片段；外源微生物的DNA片段（如病毒DNA）等。它既可以是来自于体内正常的细胞，也可能是来自肿瘤细胞，或者外源微生物。早在1948年来自法国的两位学者Mandeland Métais提出cell-free nucleic acid(cfNA)这一概念，但直到1994年科学家在肿瘤患者的血液中发现了携带有RAS基因突变的DNA片段这一概念才引起了科学家的重视。 与传统的穿刺活检相比，循环游离DNA的检测又被称为液体活检（liquid biopsy）。通过采集患者的外周血，检测血液中是否含有待检DNA序列及含量的多少来诊断患者是否患病、治疗是否有效，治疗后的复发监测等，是一种新兴的无创诊断、监测手段，所以又被形象地称为\"液体活检\"。有研究表明正常人cfDNA的含量约30ng/ml(0-100ng/ml),肿瘤患者循环血中的cfDNA含量平均约180ng/ml(0~>1000ng/ml)。虽然肿瘤患者的循环血中含有更多的cfDNA，但是单单用cfDNA的含量多少来诊断疾病或者预测患者预后可能不太可靠，来自European Prospective Investigation into Cancer andNutrition (EPIC)的大人群回顾性的研究表明cfDNA的浓度可能与人群的来源和接受治疗的不同而不同。 目前cfDNA更多的用于肿瘤的早期诊断和、疗效、复发监测等领域。近年来有大量的研究表明cfDNA的检测能够作为有效的生物标记物（biomarker）而被科学工作者所热捧，随着检测技术的发展很有可能进入临床应用。 ctDNA (Circulating tumorDNA ) 循环肿瘤DNA。是指来自肿瘤细胞的循环游离DNA。是cfDNA的一个小的亚类。研究表明一个100g的实体肿瘤大概含有3*10&#94;10个肿瘤细胞，每天大约有3.3%的肿瘤细胞DNA进入循环血。这些循环肿瘤DNA的长度基本上在70-200bp,有的能够长达21kb。这些来自肿瘤的cfDNA,常常携带有肿瘤细胞的一些特质，如特定的突变，结构改变，表观遗传信息等从而成为肿瘤的诊断、复发监测、疗效评估的有效手段。Detection of Circulating Tumor DNA in Early-and Late-Stage Human Malignancies CTC (circulatingtumor cell)循环肿瘤细胞。循环肿瘤细胞（CTCs）被认为是一种来源于肿瘤原发灶或是转移灶的，在特定条件下释放入外周血液循环的一些肿瘤细胞。这些细胞的含量非常稀少具有肿瘤细胞的特殊表型，在肿瘤发生转移之前的过程既可出现。因此CTCs也被认为是一种转移的前体细胞，是肿瘤获得侵袭性能力的体现。而如今对CTCs的无创性检测和监视，可以为肿瘤的早期诊断、疗效评估及靶向药物的设计提供一条非常有效的途径。","tags":"理论基础","url":"https://ghxdghxd.github.io/cfDNA.html"},{"title":"突变分类及定义功能","text":"概念 突变与变异是两个截然不同的概念 。 变异 一般是指物种在漫长的自然选择压力下，由于\"适者生存\"的原则而使自身遗传基因发生的某些有益于自身完善于生存环境而生存、发展的变化。 突变 则是指物种遗传基因在某些物理、化学、生物因素作用下，短期内发生的某些基因序列的变化。就人体而言，突变一般是对人体十分有害的。 突变可以分为3大类型 ：点突变（point mutation）、染色体突变(chromosomal mutation)和基因组突变(genomic mutation)。 其中以点突变最为常见和重要，包括转换(transition)、颠换（transversion）、插入(insertion)和缺失(deletion)几种类型，前两种属于碱基置换(basesubstitution)，后两种属于移码突变(frame shift mutation) 。 substitution（替换）和delection/addition(添加/缺失），估计就是碱基置换、移码、缺失和插入，只是翻译不同，这种分类有点笼统了，适合用于定义{基因突变是指DNA分子中发生碱基对的替换、增添和缺失，而引起的基因结构的改变，它包括单个碱基改变所引起的点突变（point mutation），或多个碱基的缺失、重复和插入。} 不过更笼统的是按照遗传信息的改变方式，分为错义、无义两类。 我看的分类复杂点。我看过的是类似是这个分类，你去看下网站。好象是上海一个大学的。 基因突变的类型 http://genetics.sjtu.edu.cn/genetics/21.01.htm 突变的原因 http://genetics.sjtu.edu.cn/genetics/21.02.htm 根据基因结构的改变方式不同，可将基因突变分为四种类型： （1）点突变 由某位点一对减基改变造成的。其包括两种形式：转换和颠换。点突变的不同效应为：①同义突变；②错义突变；③无义突变；④终止密码突变。 （2）移码突变 某位点增添或减少1～2对碱基造成的。 （3）缺失突变 基因内部缺失某个DNA小段造成的。 （4）插入突变 基因内部增添一小段外源DNA造成的。 基因突变是随机发生的。它可以发生在生物个体发育的任何时期和生物体的任何细胞。一般来说，在生物个体发育的过程中，基因突变发生的时期越迟，生物体表现突变的部分就越少。例如，植物的叶芽如果在发育的早期发生基因突变，那么由这个叶芽长成的枝条，上面着生的叶、花和果实都有可能与其他枝条不同。如果基因突变发生在花芽分化时，那么，将来可能只在一朵花或一个花序上表现出变异。 基因突变可以发生在体细胞中，也可以发生在生殖细胞中。发生在生殖细胞中的突变，可以通过受精作用直接传递给后代。发生在体细胞中的突变，一般是不能传递给后代的。 基因突变在生物界中是普遍存在的。无论是低等生物，还是高等的动植物以及人，都可能发生基因突变。基因突变在自然界的物种中广泛存在。例如，棉花的短果枝、水稻的矮杆、糯性，果蝇的白眼、残翅，家鸽羽毛的灰红色，以及人的色肓、糖尿病、白化病等遗传病，都是突变性状。自然条件下发生的基因突变叫做自然突变，人为条件下诱发产生的基因突变叫做诱发突变。 绝大多数的人类遗传病，就是由基因突变造成的，这些病对人类健康构成了严重威胁。又如，植物中常见的白化苗，也是基因突变形成的。这种苗由于缺乏叶绿素，不能进行光合作用制造有机物，最终导致死亡。但是，也有少数基因突变是有利的。例如，植物的抗病性突变、耐旱性突变、微生物的抗药性突变等，都是有利于生物生存的。 nonsense mutation 无义突变：使原本可制造蛋白质的密码变成停止密码 missense mutation 错义突变：使密码所对应氨基酸改变 silent mutation 无表型突变：密码改变，但对应的氨基酸不变 INV， inversion 倒位 、转置 Interchromosomal translocation, CTX 染色体间易位 intra-chromosome translocation , ITX 染色体内易位 SO term description intergenic_variant A sequence variant located in the intergenic region, between genes. upstream_gene_variant A sequence variant located 5' of a gene. (VAI searches within 5,000 bases.) downstream_gene_variant A sequence variant located 3' of a gene. (VAI searches within 5,000 bases.) 5_prime_UTR_variant A variant located in the 5' untranslated region (UTR) of a gene. 3_prime_UTR_variant A variant located in the 3' untranslated region (UTR) of a gene. synonymous_variant A sequence variant where there is no resulting change to the encoded amino acid. missense_variant A sequence variant, that changes one or more bases, resulting in a different amino acid sequence but where the length is preserved. inframe_insertion An inframe non synonymous variant that inserts bases into in the coding sequence. inframe_deletion An inframe non synonymous variant that deletes bases from the coding sequence. frameshift_variant A sequence variant which causes a disruption of the translational reading frame, because the number of nucleotides inserted or deleted is not a multiple of three. initiator_codon_variant A codon variant that changes at least one base of the first codon of a transcript. incomplete_terminal_codon_variant A sequence variant where at least one base of the final codon of an incompletely annotated transcript is changed. stop_lost A sequence variant where at least one base of the terminator codon (stop) is changed, resulting in an elongated transcript. stop_retained_variant A sequence variant where at least one base in the terminator codon is changed, but the terminator remains. exon_loss A sequence variant whereby an exon is lost from the transcript. (VAI assigns this term when an entire exon is deleted.) stop_gained A sequence variant whereby at least one base of a codon is changed, resulting in a premature stop codon, leading to a shortened transcript. NMD_transcript_variant A variant in a transcript that is already the target of nonsense-mediated decay (NMD), i.e. stop codon is not in last exon nor within 50 bases of the end of the second-to-last exon. intron_variant A transcript variant occurring within an intron. splice_donor_variant A splice variant that changes the 2-base region at the 5' end of an intron. splice_acceptor_variant A splice variant that changes the 2 base region at the 3' end of an intron. splice_region_variant A sequence variant in which a change has occurred within the region of the splice site, either within 1-3 bases of the exon or 3-8 bases of the intron. complex_transcript_variant A transcript variant with a complex insertion or deletion (indel) that spans an exon/intron border or a coding sequence/UTR border. non_coding_exon_variant A sequence variant that changes exon sequence of a non-coding gene. Functional role By default, all variants are included in the output regardless of predicted functional effect. If you would like to keep only variants that have a particular type of effect, you can uncheck the checkboxes of other effect types. The detailed functional effect predictions are categorized as follows: intergenic: intergenic_variant upstream/downstream of gene: upstream_gene_variant , downstream_gene_variant 5' or 3' UTR: 5_prime_UTR_variant , 3_prime_UTR_variant CDS - synonymous coding change: synonymous_variant CDS - non-synonymous (missense, stop gain/loss, frameshift etc): missense_variant , inframe_insertion , inframe_deletion , frameshift_variant , initiator_codon_variant , incomplete_terminal_codon_variant , stop_lost , stop_retained_variant , stop_gained , NMD_transcript_variant intron: intron_variant splice site or splice region: splice_donor_variant , splice_acceptor_variant , splice_region_variant exon of non-coding gene: non_coding_exon_variant","tags":"理论基础","url":"https://ghxdghxd.github.io/mutation.html"},{"title":"HGVS Names和refSNP ID","text":"在NCBI(美国国立生物技术信息中心)网站上经常会看到\"HGVS Names\"和\"refSNP ID\"的字样，这两个都是用于命名SNP(single nucleotide polymorphism，单核苷酸多态性)的方法。 HGVS是Human Genome Variation Society(人类基因组变异协会)的简称，是一个非政府的民间学术组织，其官方网站的 网址 。HGVS命名SNP法的规则是标出引用的核酸序列号(Reference Sequence, RefSeq)和SNP在该核酸序列中的位置，例如：NG_000004.3:g.247167G>A，其中红色的部分是核酸序列接受号，绿色的部分是该单核苷酸多态性位点在该核酸序列中的位置，G>A表示原始碱基是G，突变碱基是A。这样的命名方法有利于找出所在基因序列中的位置，当向引物公司提交设计和购买申请时都会用到。 在文献中出现的等位基因常见的标注方式，CYP3A5*3(6986A>G或A6986G)，其实这就是一种非常不正规的用HGVS Names标注SNP位置的方法，很明显，由于缺少引用核酸序列的接受号，因此读者无法从这样的表示在GenBank中查到对应的信息。这是个历史遗留问题，责任也不能全怪原文的作者标注不明，甚至有些时候，由于最初发现并报道该基因位点的文章由于没有被NCBI收录，导致有许多用此法标注的的SNP位点，其引用的RefSeq号竟然丢失了！HGVS正是做着弥补此事的工作，但是由于数据量太大，HGVS目前所完成的只是其中的一部分。所幸NCBI也看到了此事的重大意义，正在接手此事，现在在GenBank的SNP数据库的查询返回结果页的右上角已经可以看到其整理的HGVS Names了，例如： 查询CYP3A5*3的结果 。在该结果我们看到并没有标出6986A>G的HGVS命名，说明该数据库尚须完善。 GenBank官方的refSNP ID单核苷酸多态性命名法是相对比较完善的命名体系，命名方法是rs+7位阿拉伯数字，例如：CYP3A5 3的refSNP ID是rs776746，如果已知一个SNP的refSNP ID，那么就可以在GenBank的SNP数据库中搜索到相关的信息和在基因组中的位置了。这里是 GenBank的SNP数据库查询地址 ，例如，要查找CYP3A5 3在GenBank中的信息，只要在该搜索框中输入\" rs776746 \"进行查找即可。下面是该查询返回的结果，如图： 在该返回结果中可以看到给出了CYP3A5*3位点两侧少量的碱基序列，其下方给出了HGVS Names的链接，我们点击该链接，然后在接下来的网页点击\"FASTA\"链接即可获得该SNP所在的核苷酸碱基序列了，但是有些时候HGVS Names引用的核酸碱基序列较长，本示例中引用的核酸碱基序列就有几千万碱基之多，光下载都需要很长的时间，更别说在浏览器中打开了。此时可以点击上图中的红色\"rs776746\"链接，看看是否有其他引用核苷酸碱基序列较短的HGVS Names，在打开的页面的右上角可以看到有四个HGVS Names，如下： NG_000004.3:g.247167G>A NG_007938.1:g.12083G>A NM_000777.2:c.219-237G>A NT_007933.14:g.24504815C>T 其中，前两个很短，估计引用的核酸序列也较短，可以用来查看对应的核苷酸碱基序列，第三个样子有些怪，其实就是不规则命名遗留下来的，除了便于查询外，已经没有什么实际意义了。以第一个HGVS Names为例，首先打开 GenBank的Nucleotide查询数据库 ，在搜索框中输入核苷酸碱基序列\" NG_000004.3 \"，点击\"go\"键执行搜索，在返回的结果页点击\"FASTA\"链接，即可获得该SNP所在的核苷酸碱基序列了。在打开该序列的所在页面中，利用前面在SNP数据库中查到的该SNP的序列片段，依次点击IE浏览器菜单栏上的：编辑 - 在该页上查找 - 输入一段碱基序列，即可找到该SNP在此核苷酸碱基序列中的具体位置了，还可以通过点击该页面上的 \"More Formats\"链接 - \"GenBank(full)\"链接，通过网页中给出的碱基序列的位置编号来找到该SNP 所在的位置。 可能有很多人会存在这样的疑问，例如，在文献中看到类似CYP3A5*3(6986A>G)这样的等位基因名称，但此时还不知道它的refSNP ID，该如何找到该SNP在GenBank中所在的位置呢？遇到这种情况也只有在Google上碰碰运气了，因为有的文献作者会对这种残缺的HGVS Names的SNP在文章中同时标出其refSNP ID，查询的方法是在Google中输入\"该SNP的HGVS Names + refSNP ID\"进行查找即可，例如： g\"++++\"refSNP+ID\"&btnG=Google+搜索&meta=&aq=f&oq=\"target=\"_blank\" style=\"color: rgb(0, 6, 220);\"> 搜索CYP3A5*3(6986A>G) ，如果没有找到满意的检索结果，也可以直接在上文提到的GenBank的SNP数据库的搜索框中直接输入该SNP所在的基因名称+Homosapiens（人类），例如输入\" CYP3A5 Homo sapiens \"[这里需要说明的是目前只有人类的等位基因才会给出HGVS Names]，执行搜索后会返回很多该基因的SNP，每个SNP除标有refSNP ID之外，还常标出数个HGVS Names，这时就可以直接利用浏览器的网页查找功能搜索如\"_599A>G\"，_来找到对应的refSNP ID了。这里推荐的一个小窍门是，假如返回的SNP数量较多的话，可以将每页显示结果的数量设置的多一些（选择show后面的数值），会减少很多反复翻页的麻烦。","tags":"理论基础","url":"https://ghxdghxd.github.io/HGVS.html"},{"title":"之感","text":"话多应知，话少需明 前人看世界，后者品人生 棋逢对手 尽兴，将遇良才 榨干——干的漂亮 有点意思 一个男人在他该出现的时候，总也不出现，那有他和没有他，又有什么差别 数日子过年 在距今已经很久远的那一天，我们就约定好了重逢。我知道，我会找到你。《与之彼端，约定的地方》 人们的思维容易出现定势效应(set effect), 因为人们倾向于利用原有的方式解决问题，且会被困在这个思维里，无法跳出。如果 中途停下来处理其他事情，或中断了原来的情景 ，即使没有带着答案回来，也能在潜意识中明白一点，原来的思维方式可能是错的，或有新的思考方向。 这就是酝酿效应（incubation effect），指将问题搁置在一旁，能使得原有不合适的知识基础的活动性降低（减少思维定势），并采用新的方法考虑或解决问题。 定性，知事，选梦; 遇人，择城，终老。 今天是余生中最年轻的一天，想玩就玩去 爱情也许会过时，但\"爱你\"不会 此为月圆是月缺，彼是月缺为月圆，月圆盼月缺，月缺待月圆。 风起一阵知秋意， 时不时遇见，面对面错过。 三十而立，不是表面的成家或者立业，你立的，是成熟的思维模式，是独立而纵深的思考能力。 寄君一曲，不问曲终人聚散。有说顺其自然？如果有，那是否从此山水不相逢，莫道佳人长与短？ 什么是好工作：一不影响生活作息，二不影响家庭团聚，三能养家糊口。 28岁的你会不会被17岁的你嘲笑 只有当你拿起球拍，只有当你走进球场，你才会真正明白，为什么网球会如此受欢迎；只有当你背着行囊，只有当你远离一方，你才会真正明白，为什么过年如此备受期盼——数日子的日子 数日子的时间很慢，计时间的日子最快。看见的起点在远方，摸不着的终点在想… 活在梦想中 阳光不燥微风正好 我做好了要与你过一辈子的打算，也做好了你随时要走的准备 我却觉得这一大笔积分是我这辈子花的最值一次，因为我得到了钱买不来的东西……希望，从来都无法交易的东西 可否，少些理智，享受一下脱轨的惊喜 真正的离开，是没有告别的 最好的修养，是明知不问 健康大于一切 活得太过自私，想得太过周全，倒想糊涂一世，只在聪明一时，难在取舍","tags":"路由器","url":"https://ghxdghxd.github.io/the-sense.html"},{"title":"FASTQ格式详解","text":"FASTQ是基于文本的，保存生物序列（通常是核酸序列）和其测序质量信息的标准格式。 其序列以及质量信息都是使用一个ASCII字符标示，最初由Sanger开发，目的是将FASTA序列与质量数据放到一起，目前已经成为高通量测序结果的事实标准。 格式说明 FASTQ文件中每个序列通常有四行： 1.序列标识以及相关的描述信息，以‘@'开头； 2.第二行是序列 3.第三行以‘+'开头，后面是序列标示符、描述信息，或者什么也不加 4.第四行，是质量信息，和第二行的序列相对应，每一个序列都有一个质量评分，根据评分体系的不同，每个字符的含义表示的数字也不相同。 例如： @SEQ_ID GATTTGGGGTTCAAAGCAGTATCGATCAAATAGTAAATCCATTTGTTCAACTCACAGTTT \\+ ! '' * (((( ***+ )) %%%++ )( %%%% ) .1***-+* '' )) **55CCF>>>>>>CCCCCCC65 Illumina sequence identifiers @HWUSI-EAS100R:6:73:941:1973#0/1 HWUSI-EAS100R the unique instrument name 6 flowcell lane 73 tile number within the flowcell lane 941 ‘x'-coordinate of the cluster within the tile 1973 ‘y'-coordinate of the cluster within the tile #0 index number for a multiplexed sample (0 for no indexing) /1 the member of a pair, /1 or /2 _(paired-end or mate-pair reads only) @EAS139:136:FC706VJ:2:2104:15343:197393 1:Y:18:ATCACG EAS139 the unique instrument name 136 the run id FC706VJ the flowcell id 2 flowcell lane 2104 tile number within the flowcell lane 15343 ‘x'-coordinate of the cluster within the tile 197393 ‘y'-coordinate of the cluster within the tile 1 the member of a pair, 1 or 2 (paired-end or mate-pair reads only) Y Y if the read fails filter (read is bad), N otherwise 18 0 when none of the control bits are on, otherwise it is an even number ATCACG index sequence NCBI Sequence Read Archive @SRR001666.1 071112_SLXA-EAS1_s_7:5:1:817:345 length = 36 GGGTGATGGCCGCTGCCGATGGCGTCAAATCCCACC +SRR001666.1 071112_SLXA-EAS1_s_7:5:1:817:345 length = 36 IIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IG9IC 关于质量编码格式 质量评分指的是一个碱基的错误概率的对数值。其最初在Phred拼接软件中定义与使用，其后在许多软件中得到使用。其质量得分与错误概率的对应关系见下表： Phred quality scores are logarithmically linked to error probabilities Phred Quality Score Probability of incorrect base call Base call accuracy 10 1 in 10 90 % 20 1 in 100 99 % 30 1 in 1000 99.9 % 40 1 in 10000 99.99 % 50 1 in 100000 99.999 % $$Q=-10log_{10}P$$ Q: Phred quality scores P: base-calling error probabilities 除了Phred质量得分换算标准，还有就是Solexa标准： $$Q_{solexa-prior to v.1.3}=-10log_{10}\\frac{P}{1-P}$$ 两种换算标准的比较： Relationship between Q and p using the Sanger (red) and Solexa (black) equations (described above). The vertical dotted line indicates p = 0.05, or equivalently, Q ≈ 13. 对于每个碱基的质量编码标示，不同的软件采用不同的方案，目前有5种方案： Sanger，Phred quality score，值的范围从0到92，对应的ASCII码从33到126，但是对于测序数据（raw read data）质量得分通常小于60，序列拼接或者mapping可能用到更大的分数。 Solexa/Illumina 1.0, Solexa/Illumina quality score，值的范围从-5到63，对应的ASCII码从59到126，对于测序数据，得分一般在-5到40之间； Illumina 1.3+， Phred quality score ，值的范围从0到62对应的ASCII码从64到126，低于测序数据，得分在0到40之间； Illumina 1.5+，Phred quality score，但是0到2作为另外的标示， 详见 Illumina 1.8+ 下面是更为直观的表示： SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS..................................................... ..........................XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX...................... ...............................IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...................... .................................**J**JJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJ...................... LLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL.................................................... ! \"# $ %&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]&#94;_`abcdefghijklmnopqrstuvwxyz{|}~ | | | | | | 33 59 64 73 104 126 S - Sanger Phred+33, raw reads typically (0, 40) X - Solexa Solexa+64, raw reads typically (-5, 40) I - Illumina 1.3+ Phred+64, raw reads typically (0, 40) J - Illumina 1.5+ Phred+64, raw reads typically (3, 40) with 0=unused, 1=unused, 2=Read Segment Quality Control Indicator (bold) (Note: See discussion above). L - Illumina 1.8+ Phred+33, raw reads typically (0, 41)","tags":"理论基础","url":"https://ghxdghxd.github.io/fastq.html"},{"title":"MutSigCV的问题","text":"A tab-delimited report of significant mutations, listed in descending order from most significant to least significant. The \"nnei\",\"x\", and \"X\" values in the MutSig output analysis give insight into how the background mutation rate is calculated for a given gene. nnei gives the number of neighboring genes that are pooled together to compute the background mutation rate for that gene; these genes are not necessarily adjacent on the genome, but rather they have nearby covariate values. x gives the number of mutated bases in these neighboring genes that are either silent or non-coding, while X gives the total number of bases related to these neighboring genes. According to the original MutSigCV article, olfactory receptors (ORs) can show up as significant due to the heterogeneity in the mutational processes in cancer (authors' hypothesis)(Lawrence et al. \"Mutational heterogeneity in cancer and the search for new cancer-associted genes\", Nature, 2013). Certain genes, like ORs, can accumulate mutations faster than others, even if their biology is not potentially oncogenic. Therefore, assuming a uniform rate of background mutations/aberrations (GISTIC/JISTIC) is somewhat wrong, no? 肿瘤异质性的突变过程， 一些基因，如ORs，虽然对肿瘤没有功能影响，但因为能够迅速积累突变，而被鉴定出来。","tags":"生信软件","url":"https://ghxdghxd.github.io/MutSigCV.html"},{"title":"CREST的问题","text":"运行CREST时，报错如下错误： Couldn't connect to 192.168.81.177 9000 Connection refused Sorry, the BLAT/iPCR server seems to be down. Please try again later. crest第一步从原始的bam结果中提取出soft-clipped reads，第二步用blat将截短的序列，重新比对回reference。 blat有两种模式，一种是单机版(Stand - alone Blat)，另一种是交互式的客户端/服务器模式(Client/Server Blat)，CREST使用了第二种模式。 这里报这个错误，是因为没有配置好服务器。 配置服务器命令：/share/backup/user/bin/blatSuite-34/gfServer start 192.168.81.177 9000 /path_to_2bit_file/hg19.fa.2bit & （后面的&将此命令放入后台执行） 程序输出Server ready for queries!的提示后，服务器可用。 服务器配置完成后，可以用/share/backup/bin/bin/blatSuite-34/gfClient测试可否连接上服务器。若能正常连接上，则crest可正常运行。","tags":"生信软件","url":"https://ghxdghxd.github.io/CREST.html"},{"title":"脱氧核糖核酸酶高敏感位点","text":"脱氧核糖核酸酶高敏感位点（DNase Hypersensitive Site，DHS），也就是DNA酶高敏感位点，是DNA上容易被DNA酶识别的位点。 中文名脱氧核糖核酸酶高敏感位点 外文名DNase Hypersensitive Site，DHS DHS一般对应染色体上比较松弛的区段，这中松弛的特性可以提供酶去与之结合的物理条件，而那些转录活性比较强的DNA区段一般也是松弛的，因此可以通过生物信息学的方法，预测与DHS结合的转录因子信息，为DNA的功能和活性提供了重要线索。","tags":"理论基础","url":"https://ghxdghxd.github.io/DHS.html"},{"title":"linux好用软件集","text":"1. guake terminal 简介 guake terminal， 一个下拉式终端 这里下载 问题 Ctrl+D in the terminal does not close the tab anymore, but freezes the current tab ubuntu上遇到此问题，解决办法是安装 libutempter0,参考 这里 2. anaconda 简介 python 的管理工具 问题 1.matplotlib中文显示参数设置 由于matplotlib库中没有中文字体。 将对应的字体 SimHei.tff 拷贝到 ~/anaconda3/lib/python3.5/site-packages/matplotlib/mpl-data/fonts/ttf/ 在 ~/anaconda3/lib/python3.5/site-packages/matplotlib/mpl-data/matplotlibrc 中，删除font.family和font.sans-serif两行前的#，并在font.sans-serif后添加SimHei font.family :sans-serif font.sans-serif : SimHei, DejaVu Serif（后面还有很多，略去） axes.unicode_minus，将True改为False 删除~/.cache/matplotlib字体缓存","tags":"系统管理","url":"https://ghxdghxd.github.io/linux-soft.html"},{"title":"人类基因组","text":"参考序列 XY染色体上相同序列 PAR1 PAR2 chrY:10001-2649520 and chrY:59034050-59363566 chrX:60001-2699520 and chrX:154931044-155260560 参考基因组中的多余序列 The chr*_random sequences are unplaced sequence on those reference chromosomes. The chrUn_* sequences are unlocalized sequences where the corresponding reference chromosome has not been determined. 基因结构 1. 基因 ： 表达基因产物的全部DNA序列,包括启动子、5'UTR、开放阅读框(open reading frame，ORF)、外显子、内含子、3'UTR以及调控区 启动子 CAAT框(CAAT box)：其一致顺序为GGCTCAATCT，是真核生物基因常有的调节区，常位于转录起始点上游约-80bp处(或更远处)，可能也是RNA聚合酶的一个结合处，其突变敏感性决定转录效率，但是其突变不影响启动子的特异性。 开放阅读框(open reading frame，ORF)： 在mRNA上从 起始密码子 到 终止密码子 之间的一段序列，该段序列可能编码蛋白质，也可能不编码； 编码区(coding sequences，CDS): CDS是检查cDNA后得到的编码组合序列，能翻译成氨基酸序列的DNA序列，从起始密码子到终止密码子，也就是说CDS与所翻译的氨基酸序列存在严格的3对1的关系； 外显子与内含子分界 每个外显子与内含子的接头部位，都有一高度保守的共有序列，为剪接识别信号，即每个内含子5‘端的两个核苷酸都是 GT ，3‘端的两个核苷酸都是 AG ，这种连接方式称为 GT-AG 法则，是真核细胞中基因表达时剪切内含子和拼接外显子的共同机制。 2. 前信使RNA(precursor messenger RNA, pre-mRNA) 又称heterogeneous nuclear RNA, hnRNA,是转录获得的最原始序列，没有经过任何加工，序列包含从转录起始位点到转录终止位点的全部序列； 3. 信使RNA(mRNA) : 基因转录后加工成熟用于翻译蛋白质的序列，包括CDS序列、3'UTR、5'UTR、5'帽子及3'Poly(A)尾 外显子拼接形成成熟的mRNA，多数基因都有UTR,它们也是外显子拼接的产物，所以，mRNA的长度要大于CDS，只有CDS才编码蛋白，AUG以前的mRNA编码前导序列。 3`UTR的结构 : 3`UTR是PolyA尾巴的载体，而加这个尾巴关键的是PloyA signal。这个信号位点在3`UTR富含T或GT和其上游AATAAA信号中间，大约离AATAAA20-25个核苷酸，这个位点叫Cleavage site。如果AATAAA发生突变，那么PolyA signal就不会被激活。 4. cDNA ：通过mRNA反转录所得，与mRNA序列互补的单链DNA或者与mRNA对应的DNA双链； 5. EST ：表达序列标签，是指从一个随机选择的cDNA 克隆，进行5'端和3'端单一次测序挑选出来获得的短的cDNA部分序列, 代表一个完整基因的一小部分，在数据库中其长度一般从20 到7000bp 不等，平均长度为360 ±120bp。由于cDNA文库的复杂性和测序的随机性，有时多个EST代表同一基因或基因组，将其归类形成EST簇（EST cluster)； 过程|模板|原料|特点|引物 :---:|:---:|:---:|:---:|:---:|:---: DNA复制|双链DNA|四种dNTP|合成的新链与模板链一模一样，半保留复制|需要 转录|双链DNA|四种NTP|合成的新链除了把DNA上的T改为U外，其他一样，半不连续转录|不需要 翻译|mRNA|20种游离的氨基酸|3个碱基决定一个氨基酸|","tags":"理论基础","url":"https://ghxdghxd.github.io/hunman-genome.html"},{"title":"如何根据测序数据计算出数据量以及测序深度？","text":"数据量大小 单端测序 数据量 = reads长度 * reads数 双端测序 数据量 = 单端reads长度 * 单端reads个数 * 2 注： 单位换算 1个碱基=1bp 1kb=1024bp 1M=1024kb 1G=1024M 2.测序深度 测序深度 = 数据量大小 / 参考基因组大小 3.测序与物理覆盖度 在PE测序文库中","tags":"生信数据","url":"https://ghxdghxd.github.io/NGS-coverage.html"},{"title":"登录终端信息","text":"/etc/issue 在终端接口登录时候的提示字符,例如： [ root@linux ~ ] cat /etc/issue CentOS release 5 .6 ( Final ) Kernel \\r on an \\m issue内各代码说明： \\d 本地端时间的日期 \\l 显示第几个终端接口 \\m 显示硬件的等级 \\n 显示主机的网络名称 \\o 显示域名 \\r 操作系统的版本 \\t 显示本地端的时间 \\s 操作系统的名称 \\v 操作系统的版本 /etc/motd 登录后的公告消息, 比如：系统将会在某个时间进行维护 [ root@linux ~ ] vi /etc/motd Hello everyone, Our server will be maintained at please don ' t login at that time,thanks. 那么当用户登录的时候，就会显示设置的内容了。","tags":"系统管理","url":"https://ghxdghxd.github.io/terminal-announcement.html"},{"title":"集群管理笔记","text":"常用操作 电源 插座 1孔 2孔 3孔 4孔 5孔 6孔 7孔 8孔 4号 1上 1下 2下 4上 2上 3下 3上 插座3号 3号 8下 8上 7下 7上 大右 大左 2号 4下 显 交下 5下 交上 5上 1号 插座2号 小右 6左 外下 管上 6右 管下 小左 清理内存 echo 1 > /proc/sys/vm/drop_caches 登录显示信息 158挂载swap mount /dev/sdc1 /extra 核心数 /proc/cpuinfo 用来存储cpu硬件信息 一颗cpu可以有多核，加上intel的超线程技术(HT), 可以在逻辑上再分一倍数量的cpu core出来 逻辑CPU数量 = 物理cpu数量 × cpu 核数 x 2(如果支持并开启ht) 逻辑CPU 物理CPU CPU核数 最大线程数 实际服务器插槽上的CPU数目 CPU核心数 逻辑CPU数 cat /proc/cpuinfo|grep \"processor\"|wc 物理CPU数 cat /proc/cpuinfo|grep \"physical\\ id\"|sort -u|wc CPU核数 cat /proc/cpuinfo|grep \"cores\"|sort -u 硬盘 Raid0: 最少需要 2块 盘，没用冗余数据,不做备份，任何一块磁盘损坏都无法运行。n块磁盘（同类型）的阵列理论上读写速度是单块磁盘的n倍(实际达不到)，风险性也是单一n倍（实际更高），是磁盘阵列中存储性能最好的。适用于安全性不高，要求比较高性能的图形工作站或者个人站。 Raid1：至少需要 2块 *盘，磁盘数量是2的n倍，每一块磁盘要有对应的备份盘，利用率是50%，只要有一对磁盘没有损坏就可以正常使用。n组磁盘（2n块同类型磁盘）的阵列理论上读取速度是单块磁盘的n倍（实际达不到），风险性是单一磁盘的n分之一（实际更低）。换盘后需要长时间的镜像同步，不影响外界访问，但整个系统性能下降。磁盘控制器负载比较大。适用于安全性较高，且能较快恢复数据的场合。 Raid10：至少需要 4块 盘，磁盘数量也是2的n倍。既有数据镜像备份，也能保证较高的读写速度。成本比较大。 Raid3：至少需要 3块 盘（2块盘没有校验的意义）。将数据存放在n+1块盘上，有效空间是n块盘的总和，最后一块存储校验信息。数据被分割存储在n块盘上，任一数据盘出现问题，可由其他数据盘通过校正监测恢复数据（可以带伤工作），换数据盘需要重新恢复完整的校验容错信息。对阵列写入时会重写校验盘的内容，对校验盘的负载较大，读写速度相较于Raid0较慢，适用于读取多而写入少的应用环境，比如数据库和web服务器。使用容错算法和分块的大小决定了Raid3在通常情况下用于大文件且安全性要求较高的应用，比如视频编辑、硬盘播出机、大型数据库等。 Raid5：至少需要 3块 盘，读取速度接近Raid0，但是安全性更高。安全性上接近Raid1，但是磁盘的利用率更高。可以认为是Raid0和Raid1的一个折中方案。只允许有一块盘出错，可以通过另外多块盘来计算出故障盘的数据，故障之后必须尽快更换。比Raid0+1的磁盘利用率高，是目前比较常用的一种方案。 配置 commput0 [2.10GHz] * 4 * 8核/CPU * 2线程/核 = 64 1T * 6块 >>> 3T(raid10), 1.9T+792G未知 compute1-4 [2.60GHz] * 4 * 6核/CPU * 2线程/核 = 48 TeslaK20Xm GPU ，cuda核心数 2688， 内存6G compute5 [2.60GHz] * 4 * 6核/CPU * 2线程/核 = 48 compute6 [2.20GHz] * 4 * 6核/CPU * 2线程/核 = 48 compute7-8 [2.30GHz] * 4 * 8核/CPU * 2线程/核 = 64 数据线(raid5) 3T * 3块 >>> 6T 4T * 6块 >>> 18T 8T * 3块 >>> 15T 网线(raid5) 4T * 5块 >>> 16T 4T * 5块 >>> 16T 8T * 5块 >>> 30T rocks 所有节点运行 rocks run host \"hostname\" 同步配制 rocks sync config 要先重启管理节点然后计算机节点,否则导致数据不同步 rocks run host \"/etc/init.d/pbs_mom restart\" 添加用户 无法qusb要在/etc/group 添加用户 useradd -g group name passwd name rocks sync users #可更改/export/home/name 为 /home/name 如果ssh compute 需要输入密码 rm -rf ~/.ssh #然后 退出登录 再登陆 会自动生成新密钥 进入单用户模式 在倒计时5秒时，按任意键出现下图， 选择如图，按e进入编辑, 最后加上１,回车,按b,root进入系统 重装节点 rocks set host pxeboot compute1 action = install qmgr qmgr -c \"print server\" # 输出server的属性 qmgr -c \"set server query_other_jobs = true\" # qstat可以查看所有用户 qmgr -c \"set server auto_node_np = True\" # 自动更新节点线程数 multipath与iscsi操作 硬件连接及硬盘灯(绿) 确定服务开启: service iscsi restart 查看iscsi发现记录 iscsiadm -m node 发现iscsi存储： iscsiadm -m discovery -t st -p 10.1.1.100:3260 iscsiadm -m discovery -t st -p 10.1.1.101:3260 iscsiadm -m discovery -t st -p 10.1.1.102:3260 iscsiadm -m discovery -t st -p 10.1.1.103:3260 multipath操作 multipath -ll #查看 multipath -v2 #自动更新路径 multipath -f mpathg # 删除路径 service multipathd restart #重启确认/dev/mapper下有硬盘连接 # 挂载 mount /dev/mapper/mpathep1 /export/data2 mount /dev/mapper/mpathfp1 /export/data3 mount /dev/mapper/mpathhp1 /export/data4 挂载fstab /dev/sdc1 /export/data0 ext4 defaults 1 1 /dev/sdc2 /export/data1 ext4 defaults 1 1 /dev/sde1 /export/data5 ext4 defaults 1 1 /dev/mapper/mpathhp1 /export/data4 xfs defaults,_netdev 0 0 /dev/mapper/mpathep1 /export/data2 xfs defaults,_netdev 0 0 /dev/mapper/mpathfp1 /export/data3 xfs defaults,_netdev 0 0 autofs自动挂载 autofs一般与ldap、nfs协作实现远程home目录。 确认/export/*,一般重启服务 service autofs restart /etc/auto.master /share /etc/auto.share --timeout = 1200 /home /etc/auto.home --timeout = 1200 /etc/auto.share apps -nfsvers = 3 -soft,intr,timeo = 9999 xmu.local:/export/ & #bio -nfsvers=3 -soft,intr,timeo=9999 xmu:/export/& data0 -nfsvers = 3 -soft,intr,timeo = 9999 xmu.local:/export/ & data1 -nfsvers = 3 -soft,intr,timeo = 9999 xmu.local:/export/ & data2 -nfsvers = 3 -soft,intr,timeo = 9999 xmu.local:/export/ & data3 -nfsvers = 3 -soft,intr,timeo = 9999 xmu.local:/export/ & data4 -nfsvers = 3 -soft,intr,timeo = 9999 xmu.local:/export/ & data5 -nfsvers = 3 -soft,intr,timeo = 9999 xmu.local:/export/ & 修复分区(未完) exportfs -rv #重新扫描/etc/exports exportfs -u /export/data2 #umount分区 xfs_check /dev/mapper/mpathep1 ; echo $? #显示0表示已umount qsub 1.指定运行节点 qsub -l nodes = 1 :n3:ppn = 40 qusb -l nodes = 1 :n1:ppn = +1:n2 2.重新运行任务 qrerun 3.lib for i in ` seq 1 8 ` ; do sudo scp /etc/profile.d/set.sh compute-0- $i :/etc/profile.d/set.sh done rm /usr/lib64/libstdc++.so.6 ln -s /share/apps/gcc-5.3.0/lib64/libstdc++.so.6.0.21 libstdc++.so.6 strings /usr/lib/libstdc++.so.6 | grep CentOS 6.5 升级内核 rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org rpm -Uvh http://www.elrepo.org/elrepo-release-6-8.el6.elrepo.noarch.rpm yum elrepo源有 ml（mainline 为最新版本的内核）和 lt（长期支持的内核）两种内核，这里我们选择 lt 内核 yum --enablerepo = elrepo-kernel -y install kernel-lt （kernel-ml） 引导文件修改（grub.conf） 将 default 设置为 0 ，default = 0 vim /etc/grub.conf 使用 fail2ban 防御 SSH 服务器的暴力破解攻击","tags":"系统管理","url":"https://ghxdghxd.github.io/linux-management.html"},{"title":"FASTQ格式详解","text":"FASTQ 是基于文本的，保存生物序列（通常是核酸序列）和其测序质量信息的标准格式。 其序列以及质量信息都是使用一个ASCII字符标示，最初由Sanger开发，目的是将FASTA序列与质量数据放到一起，目前已经成为高通量测序结果的事实标准。 FASTQ基本格式(reads) 每条reads包括4行： 序列标识以及相关的描述信息，以‘@'开头； 第二行是序列 第三行以‘+'开头，后面是序列标示符、描述信息，或者什么也不加 第四行，是质量信息，和第二行的序列相对应，每一个序列都有一个质量评分，根据评分体系的不同，每个字符的含义表示的数字也不相同。 1 @SEQ_ID 2 GATTTGGGGTTCAAAGCAGTATCGATCAAATAGTAAATCCATTTGTTCAACTCACAGTTT 3 \\+ 4 !''*((((***+))%%%++)(%%%%).1***-+*''))**55CCF>>>>>>CCCCCCC65 Fastq ID illumina测序仪的ID行一般包含测序仪、运行编号、flowcell ID、lane ID、tile ID、横纵轴坐标、索引序列等等 质量信息 质量信息代表一个碱基的错误概率的对数值 Phred quality scores are logarithmically linked to error probabilities Phred $$Q=-10log_{10}P$$ 质量得分与错误概率的对应关系见下表： Phred Quality Score (Q) Probability of incorrect base call Base call accuracy (P) 10 1 in 10 90 % 20 1 in 100 99 % 30 1 in 1000 99.9 % 40 1 in 10000 99.99 % 50 1 in 100000 99.999 % 除了Phred质量得分换算标准，还有就是Solexa标准： $$Q_{solexa-prior to v.1.3}=-10log_{10}\\frac{P}{1-P}$$ 两种换算标准的比较： Relationship between Q and p using the Sanger (red) and Solexa (black) equations (described above). The vertical dotted line indicates p = 0.05, or equivalently, Q ≈ 13. 对于每个碱基的质量编码标示，不同的软件采用不同的方案，目前有5种方案： Sanger，Phred quality score，值的范围从0到92，对应的ASCII码从33到126，但是对于测序数据（raw read data）质量得分通常小于60，序列拼接或者mapping可能用到更大的分数。 Solexa/Illumina 1.0, Solexa/Illumina quality score，值的范围从-5到63，对应的ASCII码从59到126，对于测序数据，得分一般在-5到40之间； Illumina 1.3+， Phred quality score ，值的范围从0到62对应的ASCII码从64到126，低于测序数据，得分在0到40之间； Illumina 1.5+，Phred quality score，但是0到2作为另外的标示， 详见 Illumina 1.8+ SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS..................................................... ..........................XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX...................... ...............................IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...................... .................................**J**JJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJ...................... LLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL.................................................... !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]&#94;_`abcdefghijklmnopqrstuvwxyz{|}~ | | | | | | 33 59 64 73 104 126 S - Sanger Phred+33, raw reads typically (0, 40) X - Solexa Solexa+64, raw reads typically (-5, 40) I - Illumina 1.3+ Phred+64, raw reads typically (0, 40) J - Illumina 1.5+ Phred+64, raw reads typically (3, 40) with 0=unused, 1=unused, 2=Read Segment Quality Control Indicator (bold) (Note: See discussion above). L - Illumina 1.8+ Phred+33, raw reads typically (0, 41) fastq 质量检测工具 fastQC","tags":"生信数据","url":"https://ghxdghxd.github.io/fastq-format.html"},{"title":"R与Rstudio的安装过程（ubuntu）","text":"install R error File failed to load: /extensions/MathZoom.js export CFLAGS = \"-I/share/apps/R_depends/include\" export LDFLAGS = \"-L/share/apps/R_depends/lib\" ./configure ./configure --prefix = /opt/R-3.3.1 --enable-R-shlib --with-libpng --with-jpeglib --with-libtiff --with-x --with-tcltk 1. configure: error: No F77 compiler found sudo apt-get install gfortran 2. configure: error: --with-readline sudo apt-get install libreadline-dev 3. configure: error: --with-x=yes sudo apt-get install libxt-dev 4. checking whether zlib support suffices sudo apt-get install zlib1g-dev 5. checking whether bzip2 support suffices wget <http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz> tar xvf bzip2-1.0.6.tar.gz cd bzip2-1.0.6 sudo make install # OR make -f Makefile-libbz2_so make clean make -n install PREFIX = $R_depends make install PREFIX = $R_depends install bzip2-lib 6. configure: error: \"liblzma sudo apt-get install liblzma-dev 7. configure: error: pcre >= 8.10 wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.39.tar.gz tar xvf pcre-8.39.tar.gz cd pcre-8.39 ./configure --enable-utf8 --prefix = $R_depends make & amp ; sudo make install 8. libcurl >= 7.28.0 library and headers are required with support for https wget https://www.openssl.org/source/openssl-1.1.0b.tar.gz tar xvf openssl-1.1.0b.tar.gz cd openssl-1.1.0b ./config make & amp ; sudo make install wget <https://curl.haxx.se/download/curl-7.50.3.tar.gz> tar xvf curl-7.50.3.tar.gz cd curl-7.50.3 ./configure --with-ssl = /usr/local/ssl/ make & amp ; sudo make install 9.configure: WARNING: you cannot build info or HTML versions of the R manuals sudo apt-get install texinfo 10. configure: WARNING: you cannot build PDF versions of the R manuals, configure: WARNING: you cannot build PDF versions of vignettes and help pages sudo apt-get install texlive 11. configure: WARNING: neither inconsolata.sty nor zi4.sty found: PDF vignettes and package manuals will not be rendered optimally wget <http://mirrors.ctan.org/install/fonts/inconsolata.tds.zip> sudo mv inconsolata.tds.zip /usr/share/texlive/texmf-dist/tex/latex cd /usr/share/texlive/texmf-dist/tex/latex unzip inconsolata.tds.zip sudo mktexlsr 12. 本版本不支持png sudo apt-get install libpng16-dev sudo apt-get install libtiff5-dev make 1./usr/local/lib/libbz2.a: 无法添加符号: 错误的值 rm /usr/local/lib/libbz2.a wget <http://zlib.net/zlib-1.2.8.tar.gz> tar xvf zlib-1.2.8.tar.gz cd zlib-1.2.8 CC = 'gcc -fPIC' ./configure ; make test sudo make install 2./usr/bin/ld: cannot find -lbz2 ; collect2: error: ld returned 1 exit status sudo apt-get install libbz2-dev # 会用到 make CC = 'gcc -fPIC' make install PREFIX = /software/packages make install 1.conftest.c:1:17: fatal error: jni.h cd R-3.3.1/doc wget <https://cran.r-project.org/doc/manuals/r-release/NEWS.pdf> install rstudio sudo apt-get install libjpeg62-dev sudo apt-get install libgstreamer0.10-0 sudo apt-get install libgstreamer-plugins-base0.10-0 export RSTUDIO_WHICH_R = \"/opt/R-3.3.1/bin/R\" 添加到/etc/profile或~/.profile run R Error in grid.Call(L_textBounds, as.graphicsAnnot(xlabel),xlabel),x x, x$y, :无法载入X11字面为2,大小为20的字形- -courier-%s-%s- - -%d- - - - - - - sudo apt-get install t1-xfree86-nonfree ttf-xfree86-nonfree ttf-xfree86-nonfree-syriac sudo apt-get install xfonts-75dpi sudo apt-get install xfonts-100dpi sudo apt-get install mesa-utils sudo apt-get install libxtst-dev using R 无法载入共享目标对象 stringi.so install.packages ( stringi ) R install.packages returns \"failed to create lock directory\" R CMD INSTALL --no-lock & lt ; pkg & gt ; # OR install.packages ( \"Rcpp\" , dependencies = TRUE, INSTALL_opts = c ( '\\--no-lock' )) An irrecoverable exception occurred. R is aborting now ... ERROR: loading failed R CMD INSTALL --no-test-load *packages* nlopt ./configure --enable-shared make make install","tags":"系统管理","url":"https://ghxdghxd.github.io/R-and-Rstudio.html"},{"title":"fedora常用配置","text":"config fedora sudo rm -rf /opt sudo dnf install yum-utils package-cleanup --oldkernels RPM Fusion Free/Nonfree源, FZUG源 version = 27 sudo dnf config-manager --add-repo = http://mirrors.aliyun.com/repo/fedora.repo sudo dnf install http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release- $version .noarch.rpm -y sudo dnf install http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release- $version .noarch.rpm -y sudo dnf install https://repo.fdzh.org/FZUG/free/ $version /x86_64/noarch/fzug-release- $version -0.2.noarch.rpm -y sudo dnf makecache upgrade sudo dnf check-update & sudo dnf upgrade sudo dnf install sqlite disable Wayland /etc/gdm/custom.conf WaylandEnable=false chrome wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpm sudo dnf install ./google-chrome-stable_current_x86_64.rpm git sudo dnf install git git config --global user.name \"ghxdghxd\" git config --global user.email guojt-4451@163.com guake sudo dnf install guake gnome-tweak-tool sudo dnf install gnome-tweak-tool sudo dnf install chrome-gnome-shell dashtodocky Topicons plus wbpy sudo dnf install fcitx-table-chinese sudo dnf install fcitx-configtool sudo dnf install im-chooser im-chooser zsh sudo apt install zsh wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | zsh chsh -s /bin/zsh change PATH language export LANG=en_US xdg-user-dirs-gtk-update export LANG=zh_CN reboot install ubuntu fonts sudo dnf install ttmkfdir fontname = ubuntu-font-family-0.83 wget http://font.ubuntu.com/download/ $fontname .zip mkdir /tmp/ $fontname unzip -j $fontname .zip -d /tmp/ $fontname sudo mkdir /usr/share/fonts/ubuntu sudo mv /tmp/ $fontname /*.ttf /usr/share/fonts/ubuntu rm -rf /tmp/ $fontname cd /usr/share/fonts/ubuntu ttmkfdir > fonts.dir fc-cache -fv exFat & sshfs sudo dnf install exfat-utils sudo dnf install fuse-exfat sudo apt install sshfs synergy wget https://binaries.symless.com/v1.8.8/synergy-v1.8.8-stable-25a8cb2-Linux-x86_64.rpm sudo dnf install ./synergy-v1.8.8-stable-25a8cb2-Linux-x86_64.rpm sublime text sudo rpm -v --import https://download.sublimetext.com/sublimehq-rpm-pub.gpg sudo dnf config-manager --add-repo https://download.sublimetext.com/rpm/stable/x86_64/sublime-text.repo sudo dnf update sudo dnf install sublime-text anaconda wget https://repo.continuum.io/archive/Anaconda3-5.0.0.1-Linux-x86_64.sh bash Anaconda3-4.3.1-Linux-x86_64.sh | sh zotero wget https://download.zotero.org/client/release/5.0.23/https://download.zotero.org/client/release/5.0.23/Zotero-5.0.23_linux-x86_64.tar.bz2 tar xvf Zotero-5.0.23_linux-x86_64.tar.bz2 sudo mv Zotero_linux-x86_64/ cp /share/apps/Zotero_linux-x86_64/zotero.desktop /usr/share/applications git clone https://github.com/jlegewie/zotfile.git cd zotfile make wewechat thunderbird sudo dnf install thunderbird-enigmail atom sudo dnf --assumeyes install make gcc gcc-c++ glibc-devel git-core libsecret-devel rpmdevtools libX11-devel libxkbfile-devel sudo dnf install ./atom.x86_64.rpm wordpress sudo dnf install -y php php-mysqlnd mysql mysql-server mysql-devel workpress sudo systemctl enable httpd.service mariadb.service sudo systemctl start httpd.service mariadb.service sudo mysqladmin -u root password vi /etc/httpd/conf.d/wordpress.conf Require local ======> Require all granted sudo firewall-cmd --add-service=http --permanent sudo firewall-cmd --reload ModuleNotFoundError: No module named 'Xlib' pip install python3_xlib ModuleNotFoundError: No module named 'xdg' pip install pyxdg File failed to load: /extensions/MathZoom.jsrs install R 参考 这里","tags":"系统管理","url":"https://ghxdghxd.github.io/fedora-install.html"},{"title":"ubuntu常用配置","text":"config ubuntu upgrade sudo apt update & sudo apt upgrade chrome wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb sudo apt -fy install ./google-chrome-stable_current_amd64.deb git sudo apt install git git config --global user.name \"user name\" git config --global user.email user@email.com guake sudo apt install python-dbus-dev sudo apt install libutempter-dev sudo apt-get install automake libgconf2-dev python-glade2 libtool python-keybinder git clone https://github.com/Guake/guake.git cd guake sudo ./dev.sh --install gnome-tweak-tool sudo apt install gnome-tweak-tool sudo apt install gnome-shell-extension-dash-to-panel wbpy sudo apt install fcitx-table-wbpy im-config -s fcitx sudo cp /usr/share/fcitx/xdg/autostart/fcitx-autostart.desktop /etc/xdg/autostart/ zsh sudo apt install zsh wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | zsh chsh -s ` which zsh ` sudo shutdown -r 0 change PATH language export LANG=en_US xdg-user-dirs-gtk-update export LANG=zh_CN exFat sudo apt instal exfat-fuse sudo apt install sshfs anaconda wget https://repo.continuum.io/archive/Anaconda3-4.3.1-Linux-x86_64.sh bash Anaconda3-4.3.1-Linux-x86_64.sh | sh synergy sudo apt-get -fy install ./synergy-v1.8.8-stable-c30301e-Linux-x86_64.deb sublime sudo apt-get -fy install ./sublime-text_build-3126_amd64.deb atom sudo apt-get -fy install ./atom-amd64.deb youdao-dict sudo apt-get -fy install ./youdao-dict_1.1.0-0-deepin_amd64.deb wget https://pypi.python.org/packages/48/9a/bcf41728a0a81b3d76e2a873296c2912300c653f9e6453c760a50bd2ef93/python-xlib-0.19.tar.bz2 ModuleNotFoundError No module named 'Xlib' pip install python3_xlib No module named 'xdg' pip install pyxdg wechat sudo snap install electronic-wechat File failed to load: /extensions/MathZoom.js install R","tags":"系统管理","url":"https://ghxdghxd.github.io/ubuntu-install.html"},{"title":"分区挂载","text":"/etc/fstab 运维都知道的文件，若想把mount的disk和dir设置为每次开机自动加载，那么就要把相关信息写到这个文件中。当用\"mount -a\"命令自动mount的时候，也会去读这个文件。例如： LABEL = /hadoop/9 /hadoop/9 ext3 defaults,noatime,nodiratime,noauto 0 2 LABEL = /hadoop/10 /hadoop/10 ext3 defaults,noatime,nodiratime,noauto 0 2 /etc/mtab 这个文件主要是用mount命令的时候，系统根据实际mount的情况生成的数据，例如： /dev/sdb1 /hadoop/9 ext3 rw,noatime,nodiratime 0 0 /dev/sdc1 /hadoop/10 ext3 rw,noatime,nodiratime 0 0 /proc/mounts 这个文件是/proc/self/mounts的软链接，/proc下面的文件都是保存在内存中的，是内核自动生成的。所以/proc/mounts比/etc/mtab文件能更加真实的反映当前mount的情况 场景应用： 服务器中有一块盘因为有坏道，被umount了，通过\"df -h\"就查看不到这块盘的信息了。 或者你使用\"chmod 000 /dir\",把这块盘设为不能读不能写。 这时如果你管理了1000台服务器，你需要知道你的服务器中哪些盘是被umount了，你会怎么做？ 这里分享一个SHELL脚本，可以给你提供思路： function check_disks { for m in ` awk '$3~/ext3/ {printf\" %s \",$2}' /etc/fstab ` ; do fsdev = \"\" fsdev = ` awk -v m = $m '$2==m {print $1}' /proc/mounts ` ; if [ -z \" $fsdev \" ] ; then msg_ = \" $msg_ $m (u)\" else msg_ = \" $msg_ `awk -v m= $m ' $2 ==m { if ( $4 ~ /&#94;ro,/ ) {printf\" %s ( ro ) \", $2 } ; }' /proc/mounts`\" fi done if [ -z \" $msg_ \" ] ; then echo \"disks ok\" ; exit 0 else echo \" $msg_ \" ; exit 2 fi } 脚本首先通过比较/etc/fstab和/proc/mounts中的不同之处，得到被umount的盘，然后再把ro(read only)的盘也分析出来。 挂载usb到指定位置 blkid usb #查看uuid # 修改/etc/fstab UUID = 54A3-36E3 /home/aData exfat defaults,uid = 1000 ,gid = 1000 ,umask = 022 0 0","tags":"系统管理","url":"https://ghxdghxd.github.io/mount.html"},{"title":"ssh安装与配置","text":"相关文档 SSH安装 # 备份 sudo cp -rf /etc/ssh /etc/ssh_bak #下载 wget http://mirror.internode.on.net/pub/OpenBSD/OpenSSH/portable/openssh-7.5p1.tar.gz #解压 tar xvf openssh-7.5p1.tar.gz cd openssh-7.5p1 #编译,安装到/opt，配置保存到/etc/ssh ./configure --prefix = /opt/openssh-7.5p1 --sysconfdir = /etc/ssh --with-pam --with-zlib --with-md5-passwords make make install service sshd reload #或 service sshd restart #开机启动 chkconfig sshd on 1. 关于SSH Server的整体设定，包含使用的port以及使用的密码演算方式 Port 22 #SSH预设使用22这个port，重复使用port使用多个端口 Protocol 2 ,1 # 选择的SSH协议版本，可以是1也可以是2， # 如果要同时支持两者，就必须要使用 2,1 这个分隔了！ ListenAddress 192 .168.0.100 # 只监听来自 192.168.0.100 这个 IP 的SSH联机。 # 如果不使用设定的话，则预设所有接口均接受 SSH PidFile /var/run/sshd.pid # 可以放置 SSHD 这个 PID 的档案！左列为默认值 LoginGraceTime 600 # 当使用者连上 SSH server 之后，会出现输入密码的画面， # 在该画面中，在多久时间内没有成功连上 SSH server ， # 就断线！时间为秒！ Compression yes # 是否可以使用压缩指令？当然可以啰！ 2. 说明主机的 Private Key 放置的档案，预设使用下面的档案即可！ HostKey /etc/ssh/ssh_host_key # SSH version 1 使用的私钥 HostKey /etc/ssh/ssh_host_rsa_key # SSH version 2 使用的 RSA 私钥 HostKey /etc/ssh/ssh_host_dsa_key # SSH version 2 使用的 DSA 私钥 2.1 关于 version 1 的一些设定！ KeyRegenerationInterval 3600 # 由前面联机的说明可以知道， version 1 会使用 server 的 Public Key ，那么如果这个 Public Key 被偷的话，岂不完蛋？所以需要每隔一段时间来重新建立一次！这里的时间为秒！ ServerKeyBits 768 # 没错！这个就是 Server key 的长度！ 3. 关于登录文件的讯息数据放置与 daemon 的名称！ SyslogFacility AUTH # 当有人使用 SSH 登入系统的时候，SSH会记录资讯，这个信息要记录在什么 daemon name 底下？预设是以 AUTH 来设定的，即是 /var/log/secure 里面！什么？忘记了！回到 Linux 基础去翻一下其它可用的 daemon name 为：DAEMON,USER,AUTH,LOCAL0,LOCAL1,LOCAL2,LOCAL3,LOCAL4,LOCAL5, LogLevel INFO # 登录记录的等级！嘿嘿！任何讯息！同样的，忘记了就回去参考！ 4. 安全设定项目！极重要！ 4.1 登入设定部分 PermitRootLogin no # 是否允许 root 登入！预设是允许的，但是建议设定成 no！ UserLogin no # 在 SSH 底下本来就不接受 login 这个程序的登入！ StrictModes yes # 当使用者的 host key 改变之后，Server 就不接受联机， # 可以抵挡部分的木马程序！ # RSAAuthentication yes # 是否使用纯的 RSA 认证！？仅针对 version 1 ！ PubkeyAuthentication yes # 是否允许 Public Key ？当然允许啦！只有 version 2 AuthorizedKeysFile .ssh/authorized_keys # 上面这个在设定若要使用不需要密码登入的账号时，那么那个账号的存放档案所在档名！ 4.2 认证部分 RhostsAuthentication no # 本机系统不止使用 .rhosts ，因为仅使用 .rhosts 太不安全了，所以这里一定要设定为 no ！ IgnoreRhosts yes # 是否取消使用 ~/.ssh/.rhosts 来做为认证！当然是！ RhostsRSAAuthentication no # 这个选项是专门给 version 1 用的，使用 rhosts 档案在 /etc/hosts.equiv配合 RSA 演算方式来进行认证！不要使用 HostbasedAuthentication no # 这个项目与上面的项目类似，不过是给 version 2 使用的！ IgnoreUserKnownHosts no # 是否忽略家目录内的 ~/.ssh/known_hosts 这个档案所记录的主机内容？当然不要忽略，所以这里就是 no 啦！ PasswordAuthentication yes # 密码验证当然是需要的！所以这里写 yes 啰！ PermitEmptyPasswords no # 若上面那一项如果设定为 yes 的话，这一项就最好设定为 no ，这个项目在是否允许以空的密码登入！当然不许！ ChallengeResponseAuthentication yes # 挑战任何的密码认证！所以，任何 login.conf规定的认证方式，均可适用！ #PAMAuthenticationViaKbdInt yes # 是否启用其它的 PAM 模块！启用这个模块将会导致 PasswordAuthentication 设定失效！ 4.3 与 Kerberos 有关的参数设定！因为我们没有 Kerberos 主机，所以底下不用设定！ #KerberosAuthentication no #KerberosOrLocalPasswd yes #KerberosTicketCleanup yes #KerberosTgtPassing no 4.4 底下是有关在 X-Window 底下使用的相关设定！ X11Forwarding yes #X11DisplayOffset 10 #X11UseLocalhost yes 4.5 登入后的项目： PrintMotd no # 登入后是否显示出一些信息呢？例如上次登入的时间、地点等等，预设是 yes ，但是，如果为了安全，可以考虑改为 no ！ PrintLastLog yes # 显示上次登入的信息！可以啊！预设也是 yes ！ KeepAlive yes # 一般而言，如果设定这项目的话，那么 SSH Server 会传送 KeepAlive 的讯息给 Client 端，以确保两者的联机正常！在这个情况下，任何一端死掉后， SSH 可以立刻知道！而不会有僵尸程序的发生！ UsePrivilegeSeparation yes # 使用者的权限设定项目！就设定为 yes 吧！ MaxStartups 10 # 同时允许几个尚未登入的联机画面？当我们连上 SSH ，但是尚未输入密码时，这个时候就是我们所谓的联机画面啦！在这个联机画面中，为了保护主机，所以需要设定最大值，预设最多十个联机画面，而已经建立联机的不计算在这十个当中 4.6 关于使用者抵挡的设定项目： DenyUsers * # 设定受抵挡的使用者名称，如果是全部的使用者，那就是全部 # 挡吧！若是部分使用者，可以将该账号填入！例如下列！ DenyUsers test DenyGroups test # 与 DenyUsers 相同！仅抵挡几个群组而已！ 5. 关于 SFTP 服务的设定项目！ Subsystem sftp /usr/lib/ssh/sftp-server","tags":"系统管理","url":"https://ghxdghxd.github.io/ssh.html"},{"title":"前端","text":"css + js + html 垂直居中 display : flex ; justify-content : center ; align-items : center ;","tags":"Coding","url":"https://ghxdghxd.github.io/my-super-post.html"}]}